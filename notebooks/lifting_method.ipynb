{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2a29bd",
   "metadata": {},
   "source": [
    "# 2D to 3D Lifting Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc3068",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96be697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()   # interactive mode\n",
    "target_dir = \"../data/single_sungaya/\"\n",
    "out_df = pd.read_hdf(os.path.join(target_dir, \"Data_3D_Pose.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc82a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def set_axes_equal(ax):\n",
    "    # workaround, as matplotlib's 3D plot has no option for equisised axes (10/2021)\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2da8a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BugDataset(Dataset):\n",
    "    \"\"\"Bug dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, hdf_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hdf_file (string): Path to the hdf file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.bugs_frame = pd.read_hdf(hdf_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bugs_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.bugs_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        df_columns = self.bugs_frame.columns.values.tolist()\n",
    "        sample = {'image':image}\n",
    " \n",
    "        for x in range(len(df_columns)):    \n",
    "            sample[df_columns[x]] = self.bugs_frame.iloc[idx,x]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        sample_keys = list(sample.keys())\n",
    "        sample_data = list(sample.values())\n",
    "\n",
    "        dic ={'image': torch.from_numpy(image)}\n",
    "        dic[sample_keys[1]] =  sample_data[1]\n",
    "        for x in range(2,len(sample_keys)):\n",
    "            dic[sample_keys[x]] = torch.FloatTensor(sample_data[x])\n",
    "        return dic\n",
    "class Normalize(object):\n",
    "    def __init__(self,means_2, means_3, std_2, std_3):\n",
    "        self.means_2 =means_2\n",
    "        self.means_3 = means_3\n",
    "        self.std_2 = std_2\n",
    "        self.std_3 = std_3\n",
    "    def __call__(self, sample):\n",
    "        # print(\"Bruh\")\n",
    "        image = sample['image']\n",
    "        dic ={'image': image}\n",
    "        sample_keys = list(sample.keys())\n",
    "        sample_data = list(sample.values())\n",
    "\n",
    "        dic[sample_keys[1]] =  sample_data[1]\n",
    "        for x in range(2,len(sample_keys)):\n",
    "            if sample_keys[x]== 'key_points_2D':\n",
    "                dic[sample_keys[x]] = (sample_data[x]-self.means_2)/self.std_2\n",
    "            elif sample_keys[x]== 'key_points_3D':\n",
    "                dic[sample_keys[x]] = (sample_data[x]-self.means_3)/self.std_3\n",
    "            else:\n",
    "                dic[sample_keys[x]] = sample_data[x]\n",
    "        return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e318dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.read_hdf(\"../data/single_sungaya/Data_3D_Pose.hdf5\")\n",
    "array_2d = np.array(out_df['key_points_2D'].to_numpy())\n",
    "array_3d = np.array(out_df['key_points_3D'].to_numpy())\n",
    "\n",
    "for x in range(len(array_2d)):\n",
    "    array_2d[x] = np.array(array_2d[x])\n",
    "    array_3d[x] = np.array(array_3d[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b3f8935",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_array_2d = np.empty((3778,124))\n",
    "fixed_array_3d = np.empty((3778,186))\n",
    "for x in range(len(fixed_array_2d)):\n",
    "    z = array_2d[x].reshape(1,124)\n",
    "    fixed_array_2d[x] = z\n",
    "for x in range(len(fixed_array_3d)):\n",
    "    z = array_3d[x].reshape(1,186)\n",
    "    fixed_array_3d[x] = z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8766073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_2d = np.mean(fixed_array_2d, axis=0).reshape((62,2))\n",
    "# print(means_2d)\n",
    "means_3d = np.mean(fixed_array_3d, axis=0).reshape((62,3))\n",
    "std_2d =  np.std(fixed_array_2d, axis=0).reshape((62,2))\n",
    "# print(std_2d)\n",
    "std_3d = np.std(fixed_array_3d, axis=0).reshape((62,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4a8ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sungaya_dataset = BugDataset(hdf_file='../data/single_sungaya/Data_3D_Pose.hdf5',\n",
    "                             root_dir=target_dir,transform=transforms.Compose([\n",
    "                                Normalize(means_2d, means_3d, std_2d, std_3d),\n",
    "                                ToTensor()\n",
    "                                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85d25c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8686,  0.6842],\n",
       "        [-0.8116,  0.4713],\n",
       "        [-0.7497,  0.2839],\n",
       "        [-0.5250,  0.0509],\n",
       "        [-0.3587, -0.0988],\n",
       "        [-0.1519, -0.2003],\n",
       "        [ 0.0839, -0.2949],\n",
       "        [-0.8656,  0.5973],\n",
       "        [-0.8770,  0.5889],\n",
       "        [-0.8927,  0.5843],\n",
       "        [-1.0051,  0.4992],\n",
       "        [-0.9195,  0.4978],\n",
       "        [-0.8637,  0.5105],\n",
       "        [-0.8301,  0.5497],\n",
       "        [-0.7952,  0.2831],\n",
       "        [-0.8161,  0.2482],\n",
       "        [-0.8308,  0.1988],\n",
       "        [-0.9168, -0.0765],\n",
       "        [-0.8822, -0.2424],\n",
       "        [-0.8526, -0.3063],\n",
       "        [-0.8439, -0.3324],\n",
       "        [-0.7089,  0.1457],\n",
       "        [-0.7293,  0.0777],\n",
       "        [-0.7284,  0.0457],\n",
       "        [-0.6971, -0.0580],\n",
       "        [-0.6021, -0.5537],\n",
       "        [-0.5735, -0.6162],\n",
       "        [-0.5761, -0.6448],\n",
       "        [-0.8319,  0.3237],\n",
       "        [-0.7943,  0.6819],\n",
       "        [-0.7348,  0.7465],\n",
       "        [-0.5272,  0.9594],\n",
       "        [-0.3697,  1.1239],\n",
       "        [-0.2959,  1.2255],\n",
       "        [-0.2571,  1.3187],\n",
       "        [-0.7424,  0.3871],\n",
       "        [-0.7127,  0.4394],\n",
       "        [-0.7001,  0.4898],\n",
       "        [-0.6342,  0.8355],\n",
       "        [-0.4892,  1.0264],\n",
       "        [-0.4227,  1.1257],\n",
       "        [-0.3606,  1.1912],\n",
       "        [-0.6814,  0.2282],\n",
       "        [-0.6034,  0.2760],\n",
       "        [-0.5775,  0.2840],\n",
       "        [-0.0713,  0.5006],\n",
       "        [ 0.0659,  0.3199],\n",
       "        [ 0.2774,  0.3341],\n",
       "        [ 0.3647,  0.3602],\n",
       "        [-0.7532,  0.4414],\n",
       "        [-0.8382,  0.7349],\n",
       "        [-0.8310,  0.7615],\n",
       "        [-0.8628,  0.7876],\n",
       "        [-0.8835,  0.8953],\n",
       "        [-0.8197,  1.1423],\n",
       "        [-0.7669,  1.1439],\n",
       "        [-0.8382,  0.7349],\n",
       "        [-0.7883,  0.8223],\n",
       "        [-0.8210,  0.8510],\n",
       "        [-0.7928,  1.0489],\n",
       "        [-0.5830,  1.4096],\n",
       "        [-0.4393,  1.5057]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sungaya_dataset[0]['key_points_2D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f068e49b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d6a49b9a4ad48d99dc5e40b871f4d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = sungaya_dataset[69]\n",
    "# print(sample)\n",
    "image = sample[\"file_name\"]\n",
    "plt.figure()\n",
    "plt.imshow(io.imread(os.path.join(target_dir,image)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02b63446",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(sungaya_dataset))\n",
    "test_size = len(sungaya_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(sungaya_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5362d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "263dbf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=124, out_features=248, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=248, out_features=248, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=248, out_features=62, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(62*2, 248),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(248, 248),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(248, 62)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "    \n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e3a63f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ipdb\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b451fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        X = data['key_points_2D']\n",
    "        y = data['key_points_3D'][:,:,2]\n",
    "        X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ff1a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "#             print(data['key_points_2D'])\n",
    "            X = data['key_points_2D']\n",
    "            y = data['key_points_3D'][:,:,2]\n",
    "            X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "588a064a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.974734  [    0/ 3022]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (62) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JONATH~1\\AppData\\Local\\Temp/ipykernel_26548/2327223415.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\JONATH~1\\AppData\\Local\\Temp/ipykernel_26548/167272304.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mcorrect\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (62) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c9ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983795ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
