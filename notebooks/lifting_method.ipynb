{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2a29bd",
   "metadata": {},
   "source": [
    "# 2D to 3D Lifting Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc3068",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96be697e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x1e1b4ffe940>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc82a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def set_axes_equal(ax):\n",
    "    # workaround, as matplotlib's 3D plot has no option for equisised axes (10/2021)\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2da8a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BugDataset(Dataset):\n",
    "    \"\"\"Bug dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hdf_file (string): Path to the hdf file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.bugs_frame = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bugs_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.bugs_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        df_columns = self.bugs_frame.columns.values.tolist()\n",
    "        sample = {'image':image}\n",
    " \n",
    "        for x in range(len(df_columns)):    \n",
    "            sample[df_columns[x]] = self.bugs_frame.iloc[idx,x]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        sample_keys = list(sample.keys())\n",
    "        sample_data = list(sample.values())\n",
    "\n",
    "        dic ={'image': torch.from_numpy(image)}\n",
    "        dic[sample_keys[1]] = sample_data[1]\n",
    "        for x in range(2,len(sample_keys)):\n",
    "            dic[sample_keys[x]] = torch.FloatTensor(sample_data[x])\n",
    "        return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c44946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"../data/single_sungaya/\"\n",
    "out_df = pd.read_hdf(os.path.join(target_dir, \"Data_3D_Pose.hdf5\"))\n",
    "new_df = pd.DataFrame()\n",
    "for col, x in out_df.iterrows():\n",
    "    if x['visibility'][2]==1:\n",
    "        new_df = new_df.append(x)\n",
    "new_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "new_df['key_points_2D'] = new_df['key_points_2D'].apply(np.array)\n",
    "new_df['key_points_3D'] = new_df['key_points_3D'].apply(np.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d91771f",
   "metadata": {},
   "source": [
    "## Centralise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "918dd066",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint = 3\n",
    "def centralise_2d(sample):\n",
    "    x_diff, y_diff = sample[keypoint-1][0], sample[keypoint-1][1]\n",
    "    for i in range(len(sample)):\n",
    "        sample[i][0] = sample[i][0] - x_diff\n",
    "        sample[i][1] = sample[i][1] - y_diff\n",
    "    return sample\n",
    "def centralise_3d(sample):\n",
    "    x_diff, y_diff, z_diff = sample[keypoint-1][0], sample[keypoint-1][1], sample[keypoint-1][2]\n",
    "    for i in range(len(sample)):\n",
    "        sample[i][0] = sample[i][0] - x_diff\n",
    "        sample[i][1] = sample[i][1] - y_diff\n",
    "        sample[i][2] = sample[i][2] - z_diff\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dffce916",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['key_points_2D'] = new_df['key_points_2D'].apply(centralise_2d)\n",
    "new_df['key_points_3D'] = new_df['key_points_3D'].apply(centralise_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aef997",
   "metadata": {},
   "source": [
    "## Normalise Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e318dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2d = np.array(new_df['key_points_2D'].to_numpy())\n",
    "array_3d = np.array(new_df['key_points_3D'].to_numpy())\n",
    "\n",
    "for x in range(len(array_2d)):\n",
    "    array_2d[x] = np.array(array_2d[x])\n",
    "    array_3d[x] = np.array(array_3d[x])\n",
    "\n",
    "fixed_array_2d = np.empty((len(array_2d),124))\n",
    "fixed_array_3d = np.empty((len(array_3d),186))\n",
    "for x in range(len(fixed_array_2d)):\n",
    "    z = array_2d[x].reshape(1,124)\n",
    "    fixed_array_2d[x] = z\n",
    "for x in range(len(fixed_array_3d)):\n",
    "    z = array_3d[x].reshape(1,186)\n",
    "    fixed_array_3d[x] = z\n",
    "\n",
    "means_2d = np.mean(fixed_array_2d, axis=0).reshape((62,2))\n",
    "means_3d = np.mean(fixed_array_3d, axis=0).reshape((62,3))\n",
    "std_2d =  np.std(fixed_array_2d, axis=0).reshape((62,2))\n",
    "std_3d = np.std(fixed_array_3d, axis=0).reshape((62,3))\n",
    "\n",
    "def normal_2(x):\n",
    "    return np.nan_to_num((x-means_2d)/std_2d)\n",
    "def normal_3(x):\n",
    "    return np.nan_to_num((x-means_3d)/std_3d)\n",
    "\n",
    "new_df['key_points_2D'] = new_df['key_points_2D'].apply(normal_2)\n",
    "new_df['key_points_3D'] = new_df['key_points_3D'].apply(normal_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4a8ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sungaya_dataset = BugDataset(df=new_df,\n",
    "                             root_dir=target_dir,transform=transforms.Compose([\n",
    "                                ToTensor()\n",
    "                                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f068e49b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0600e21107dd419786ec254167c9a073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = sungaya_dataset[1]\n",
    "# print(sample)\n",
    "image = sample[\"file_name\"]\n",
    "plt.figure()\n",
    "plt.imshow(io.imread(os.path.join(target_dir,image)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b63446",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.7\n",
    "valid_split = 0.1\n",
    "train_size = int(train_split * len(sungaya_dataset))\n",
    "valid_size = int(valid_split * len(sungaya_dataset))\n",
    "test_size = len(sungaya_dataset) - (train_size+valid_size)\n",
    "train_dataset,valid_dataset ,test_dataset = torch.utils.data.random_split(sungaya_dataset, [train_size, valid_size, test_size], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5362d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "263dbf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))    \n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_inputs,hidden,n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.seq1 = nn.Sequential(\n",
    "            nn.Linear(n_inputs, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, n_inputs)\n",
    "        )\n",
    "        self.seq2 = nn.Sequential(\n",
    "            nn.Linear(n_inputs, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, n_inputs)\n",
    "        )\n",
    "        self.out = nn.Linear(n_inputs, n_output)\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        residual = x\n",
    "        out = self.seq1(x)\n",
    "        out+=residual\n",
    "        out = self.seq2(out)\n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b451fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JONATH~1\\AppData\\Local\\Temp/ipykernel_1472/2738829921.py:2: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  accdists = np.nan_to_num(abs((actual_dist-means_3d)/std_3d))\n"
     ]
    }
   ],
   "source": [
    "actual_dist=[4,4,4]\n",
    "accdists = np.nan_to_num(abs((actual_dist-means_3d)/std_3d))\n",
    "accz_dists = torch.from_numpy(accdists.T[2])\n",
    "#                  Body       r_1       r_2       r_3       l_1       l_2       l_3       r_an      l_an\n",
    "reducedKeypoints = [0,3,4,6 , 7,10,13 , 14,17,20, 21,24,27, 28,31,34, 35,38,41, 42,45,48, 52,53,55, 58,59,61]\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, reducedkey):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        if reducedkey:\n",
    "            X = data['key_points_2D'][reducedKeypoints,:]\n",
    "            y = data['key_points_3D'][reducedKeypoints,:,2]\n",
    "            mask = data['visibility'].to(device)\n",
    "        else:\n",
    "            X = data['key_points_2D']\n",
    "            y = data['key_points_3D'][:,:,2]\n",
    "            mask = data['visibility'].to(device)\n",
    "\n",
    "        X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = torch.mean(((pred - y)*mask)**2)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "#             print(data['key_points_2D'])\n",
    "            if reducedkey:\n",
    "                X = data['key_points_2D'][reducedKeypoints,:]\n",
    "                y = data['key_points_3D'][reducedKeypoints,:,2]\n",
    "                mask = data['visibility'].to(device)\n",
    "            else:\n",
    "                X = data['key_points_2D']\n",
    "                y = data['key_points_3D'][:,:,2]\n",
    "                mask = data['visibility'].to(device)\n",
    "\n",
    "            X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "            pred = model(X)\n",
    "            loss = torch.mean(((pred - y)*mask)**2)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            correct += (abs(pred - y)<accz_dists.to(device)).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Validation Error: \\n Accuracy: {(correct / size):>4f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "588a064a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.400994  [    0/ 2286]\n",
      "Validation Error: \n",
      " Accuracy: 43.042945%, Avg loss: 0.366483 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.370227  [    0/ 2286]\n",
      "Validation Error: \n",
      " Accuracy: 43.730061%, Avg loss: 0.345035 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.345906  [    0/ 2286]\n",
      "Validation Error: \n",
      " Accuracy: 44.337423%, Avg loss: 0.327393 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.326407  [    0/ 2286]\n",
      "Validation Error: \n",
      " Accuracy: 44.788344%, Avg loss: 0.312706 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.310549  [    0/ 2286]\n",
      "Validation Error: \n",
      " Accuracy: 45.263804%, Avg loss: 0.300336 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = Net(2*62,512,62).to(device)\n",
    "reduceKeypoints = False\n",
    "epochs = 5\n",
    "learning_rate =5e-3\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer, reduceKeypoints)\n",
    "    test(valid_dataloader, model, loss_fn, reduceKeypoints)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983795ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        image = data['file_name']\n",
    "        print(image)\n",
    "        vis = data['visibility'].numpy()\n",
    "        X = data['key_points_2D']\n",
    "        y = data['key_points_3D']\n",
    "        vis = data['visibility']\n",
    "        # print(y)\n",
    "        X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "        pred = model(X)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f6ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stick_bug(ax, points, vis=None, simple=False):\n",
    "    limb_ranges=[[0,7],[8,14],[15,21],[22,28],[29,35],[36,42],[43,49],[53,56],[59,62]]\n",
    "    if len(points) < 62:\n",
    "        return\n",
    "    elif len(points) == 62:\n",
    "        points = np.array(points).T\n",
    "        print(points)\n",
    "        if not simple:\n",
    "            for (fr,end) in limb_ranges:\n",
    "                # print(vis.numpy())\n",
    "                # if vis[fr:] == 1 or vis[end-1] == 1:\n",
    "                ax.plot(points[0][fr:end], points[1][fr:end], points[2][fr:end])\n",
    "                ax.scatter(points[0][fr:end], points[1][fr:end], points[2][fr:end], marker='o',s=10)\n",
    "            return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a373ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 0\n",
    "print(image[sample])\n",
    "# prediction = (pred[sample].cpu()).numpy()\n",
    "actual = (y[sample].cpu()).numpy()\n",
    "\n",
    "\n",
    "mean = means_3d[:,2]\n",
    "std = std_3d[:,2]\n",
    "\n",
    "# unnormalised_est = (prediction*std)+mean\n",
    "unnormalised_acc = (actual*std_3d)+means_3d\n",
    "# print(unnormalised_est)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "# for i in range(len(unnormalised_acc)):\n",
    "#     # ax.scatter(unnormalised_acc[i,0], unnormalised_acc[i,1], unnormalised_acc[i,2], marker='o',s=10)\n",
    "    # ax.scatter(unnormalised_acc[i,0], unnormalised_acc[i,1], unnormalised_est[i], marker='x',s=10)\n",
    "#     # print(\"Differences Point:\", i, np.abs(unnormalised_acc[i,2]-unnormalised_est[i]))\n",
    "\n",
    "plot_stick_bug(ax, unnormalised_acc)\n",
    "\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "ax.set_zlabel('Z axis')\n",
    "\n",
    "# use custom function to ensure equal axis proportions\n",
    "set_axes_equal(ax)\n",
    "\n",
    "# opens external plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
