{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2a29bd",
   "metadata": {},
   "source": [
    "# 2D to 3D Lifting Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc3068",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96be697e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x25cf8deabe0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc82a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def set_axes_equal(ax):\n",
    "    # workaround, as matplotlib's 3D plot has no option for equisised axes (10/2021)\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2da8a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BugDataset(Dataset):\n",
    "    \"\"\"Bug dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hdf_file (string): Path to the hdf file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.bugs_frame = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bugs_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.bugs_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        df_columns = self.bugs_frame.columns.values.tolist()\n",
    "        sample = {'image':image}\n",
    " \n",
    "        for x in range(len(df_columns)):    \n",
    "            sample[df_columns[x]] = self.bugs_frame.iloc[idx,x]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        sample_keys = list(sample.keys())\n",
    "        sample_data = list(sample.values())\n",
    "\n",
    "        dic ={'image': torch.from_numpy(image)}\n",
    "        dic[sample_keys[1]] =  sample_data[1]\n",
    "        for x in range(2,len(sample_keys)):\n",
    "            dic[sample_keys[x]] = torch.FloatTensor(sample_data[x])\n",
    "        return dic\n",
    "\n",
    "class Centralize(object):\n",
    "    def __init__(self, keypoint=3):\n",
    "        self.center_keypoint = keypoint\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "        dic ={'image': image}\n",
    "        sample_keys = list(sample.keys())\n",
    "        sample_data = list(sample.values())\n",
    "\n",
    "        dic[sample_keys[1]] =  sample_data[1]\n",
    "        for x in range(2,len(sample_keys)):\n",
    "            if sample_keys[x]== 'key_points_2D':\n",
    "                x_diff, y_diff = sample_data[x][self.center_keypoint-1][0], sample_data[x][self.center_keypoint-1][1]\n",
    "                for i in range(len(sample_data[x])):\n",
    "                    sample_data[x][i][0] = sample_data[x][i][0] - x_diff\n",
    "                    sample_data[x][i][1] = sample_data[x][i][1] - y_diff\n",
    "                dic[sample_keys[x]] = sample_data[x]\n",
    "            elif sample_keys[x]== 'key_points_3D':\n",
    "                x_diff, y_diff, z_diff = sample_data[x][self.center_keypoint-1][0], sample_data[x][self.center_keypoint-1][1], sample_data[x][self.center_keypoint-1][2]\n",
    "                for i in range(len(sample_data[x])):\n",
    "                    sample_data[x][i][0] = sample_data[x][i][0] - x_diff\n",
    "                    sample_data[x][i][1] = sample_data[x][i][1] - y_diff\n",
    "                    sample_data[x][i][2] = sample_data[x][i][2] - z_diff\n",
    "                dic[sample_keys[x]] = sample_data[x]\n",
    "            else:\n",
    "                dic[sample_keys[x]] = sample_data[x]\n",
    "        return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c44946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"../data/single_sungaya/\"\n",
    "out_df = pd.read_hdf(os.path.join(target_dir, \"Data_3D_Pose.hdf5\"))\n",
    "new_df = pd.DataFrame()\n",
    "for col, x in out_df.iterrows():\n",
    "    if x['visibility'][2]==1:\n",
    "        new_df = new_df.append(x)\n",
    "new_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "new_df['key_points_2D'] = new_df['key_points_2D'].apply(np.array)\n",
    "new_df['key_points_3D'] = new_df['key_points_3D'].apply(np.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aef997",
   "metadata": {},
   "source": [
    "## Normalise Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e318dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2d = np.array(new_df['key_points_2D'].to_numpy())\n",
    "array_3d = np.array(new_df['key_points_3D'].to_numpy())\n",
    "\n",
    "for x in range(len(array_2d)):\n",
    "    array_2d[x] = np.array(array_2d[x])\n",
    "    array_3d[x] = np.array(array_3d[x])\n",
    "\n",
    "fixed_array_2d = np.empty((len(array_2d),124))\n",
    "fixed_array_3d = np.empty((len(array_3d),186))\n",
    "for x in range(len(fixed_array_2d)):\n",
    "    z = array_2d[x].reshape(1,124)\n",
    "    fixed_array_2d[x] = z\n",
    "for x in range(len(fixed_array_3d)):\n",
    "    z = array_3d[x].reshape(1,186)\n",
    "    fixed_array_3d[x] = z\n",
    "\n",
    "means_2d = np.mean(fixed_array_2d, axis=0).reshape((62,2))\n",
    "means_3d = np.mean(fixed_array_3d, axis=0).reshape((62,3))\n",
    "std_2d =  np.std(fixed_array_2d, axis=0).reshape((62,2))\n",
    "std_3d = np.std(fixed_array_3d, axis=0).reshape((62,3))\n",
    "\n",
    "def normal_2(x):\n",
    "    return (x-means_2d)/std_2d\n",
    "def normal_3(x):\n",
    "    return (x-means_3d)/std_3d\n",
    "\n",
    "new_df['key_points_2D'] = new_df['key_points_2D'].apply(normal_2)\n",
    "new_df['key_points_3D'] = new_df['key_points_3D'].apply(normal_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a8ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sungaya_dataset = BugDataset(df=new_df,\n",
    "                             root_dir=target_dir,transform=transforms.Compose([\n",
    "                                Centralize(),\n",
    "                                ToTensor()\n",
    "                                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f068e49b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1dcf1c279d842c0b3a45eb37b68a377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = sungaya_dataset[1]\n",
    "# print(sample)\n",
    "image = sample[\"file_name\"]\n",
    "plt.figure()\n",
    "plt.imshow(io.imread(os.path.join(target_dir,image)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b63446",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.7\n",
    "valid_split = 0.1\n",
    "train_size = int(train_split * len(sungaya_dataset))\n",
    "valid_size = int(valid_split * len(sungaya_dataset))\n",
    "test_size = len(sungaya_dataset) - (train_size+valid_size)\n",
    "train_dataset,valid_dataset ,test_dataset = torch.utils.data.random_split(sungaya_dataset, [train_size, valid_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5362d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "263dbf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))    \n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_inputs,hidden,n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.seq1 = nn.Sequential(\n",
    "            nn.Linear(n_inputs, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, n_inputs)\n",
    "        )\n",
    "        self.seq2 = nn.Sequential(\n",
    "            nn.Linear(n_inputs, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, n_inputs)\n",
    "        )\n",
    "        self.out = nn.Linear(n_inputs, n_output)\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        residual = x\n",
    "        out = self.seq1(x)\n",
    "        out+=residual\n",
    "        out = self.seq2(out)\n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "5b451fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_dist=[4,4,4]\n",
    "accdists = abs((actual_dist-means_3d)/std_3d)\n",
    "accz_dists = torch.from_numpy(accdists.T[2])\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        X = data['key_points_2D']\n",
    "        y = data['key_points_3D'][:,:,2]\n",
    "        mask = data['visibility']\n",
    "        X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "\n",
    "        # ## Calculate mask\n",
    "        # z = np.repeat(mask, repeats=124, axis=0)\n",
    "        # print(z.shape)\n",
    "        # z = z.reshape((64,62,2))\n",
    "        # X = X*z\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "#             print(data['key_points_2D'])\n",
    "            X = data['key_points_2D']\n",
    "            y = data['key_points_3D'][:,:,2]\n",
    "            # print(y)\n",
    "            X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "            correct += (abs(pred - y)<accz_dists.to(device)).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Validation Error: \\n Accuracy: {(correct / size):>4f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "588a064a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.862072  [    0/ 2286]\n",
      "Validation Error: \n",
      " Accuracy: 55.733129%, Avg loss: 1.882792 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.771211  [    0/ 2286]\n",
      "Validation Error: \n",
      " Accuracy: 55.843558%, Avg loss: 1.823327 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.702048  [    0/ 2286]\n",
      "Validation Error: \n",
      " Accuracy: 55.978528%, Avg loss: 1.776935 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.647776  [    0/ 2286]\n",
      "Validation Error: \n",
      " Accuracy: 56.088957%, Avg loss: 1.739451 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.603825  [    0/ 2286]\n",
      "Validation Error: \n",
      " Accuracy: 56.196319%, Avg loss: 1.708098 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = Net(2*62,512,62).to(device)\n",
    "\n",
    "epochs = 5\n",
    "learning_rate =5e-3\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(valid_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "983795ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9832_Img_synth.png', '4439_Img_synth.png', '5589_Img_synth.png', '9929_Img_synth.png', '3888_Img_synth.png', '3330_Img_synth.png', '660_Img_synth.png', '6153_Img_synth.png', '3999_Img_synth.png', '2243_Img_synth.png', '3280_Img_synth.png', '8195_Img_synth.png', '3887_Img_synth.png', '1815_Img_synth.png', '9520_Img_synth.png', '853_Img_synth.png', '2519_Img_synth.png', '5559_Img_synth.png', '3894_Img_synth.png', '2786_Img_synth.png', '4271_Img_synth.png', '9687_Img_synth.png', '4616_Img_synth.png', '6666_Img_synth.png', '8465_Img_synth.png', '5722_Img_synth.png', '1619_Img_synth.png', '5527_Img_synth.png', '9034_Img_synth.png', '3514_Img_synth.png', '9575_Img_synth.png', '7880_Img_synth.png', '9872_Img_synth.png', '7501_Img_synth.png', '2596_Img_synth.png', '9066_Img_synth.png', '3166_Img_synth.png', '8291_Img_synth.png', '305_Img_synth.png', '2393_Img_synth.png', '2341_Img_synth.png', '1875_Img_synth.png', '9458_Img_synth.png', '7841_Img_synth.png', '777_Img_synth.png', '268_Img_synth.png', '7076_Img_synth.png', '8679_Img_synth.png', '4687_Img_synth.png', '9150_Img_synth.png', '7757_Img_synth.png', '9611_Img_synth.png', '6861_Img_synth.png', '414_Img_synth.png', '6465_Img_synth.png', '6039_Img_synth.png', '6539_Img_synth.png', '7878_Img_synth.png', '8901_Img_synth.png', '7274_Img_synth.png', '2187_Img_synth.png', '7836_Img_synth.png', '4628_Img_synth.png', '997_Img_synth.png']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        image = data['file_name']\n",
    "        print(image)\n",
    "        vis = data['visibility'].numpy()\n",
    "        X = data['key_points_2D']\n",
    "        y = data['key_points_3D']\n",
    "        vis = data['visibility']\n",
    "        # print(y)\n",
    "        X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "        pred = model(X)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "97f6ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stick_bug(ax, points, vis, simple=False):\n",
    "    limb_ranges=[[0,7],[8,14],[15,21],[22,28],[29,35],[36,42],[43,49],[53,56],[59,62]]\n",
    "    if len(points) < 62:\n",
    "        return\n",
    "    elif len(points) == 62:\n",
    "        points = np.array(points).T\n",
    "        if not simple:\n",
    "            for (fr,end) in limb_ranges:\n",
    "                # print(vis.numpy())\n",
    "                # if vis[fr:] == 1 or vis[end-1] == 1:\n",
    "                ax.plot(points[0][fr:end], points[1][fr:end], points[2][fr:end])\n",
    "                ax.scatter(points[0][fr:end], points[1][fr:end], points[2][fr:end], marker='o',s=10)\n",
    "            return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "e6a373ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9929_Img_synth.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191d2017daa24994b1d0fdcf3e56cf18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = 3\n",
    "print(image[sample])\n",
    "prediction = (pred[sample].cpu()).numpy()\n",
    "actual = (y[sample].cpu()).numpy()\n",
    "\n",
    "\n",
    "mean = means_3d[:,2]\n",
    "std = std_3d[:,2]\n",
    "\n",
    "unnormalised_est = (prediction*std)+mean\n",
    "unnormalised_acc = (actual*std_3d)+means_3d\n",
    "# print(unnormalised_est)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "for i in range(len(unnormalised_acc)):\n",
    "    # ax.scatter(unnormalised_acc[i,0], unnormalised_acc[i,1], unnormalised_acc[i,2], marker='o',s=10)\n",
    "    ax.scatter(unnormalised_acc[i,0], unnormalised_acc[i,1], unnormalised_est[i], marker='x',s=10)\n",
    "    # print(\"Differences Point:\", i, np.abs(unnormalised_acc[i,2]-unnormalised_est[i]))\n",
    "\n",
    "plot_stick_bug(ax, unnormalised_acc, vis[sample])\n",
    "\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "ax.set_zlabel('Z axis')\n",
    "\n",
    "# use custom function to ensure equal axis proportions\n",
    "set_axes_equal(ax)\n",
    "\n",
    "# opens external plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "ead21a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7688,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 7688 into shape (64,62,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JONATH~1\\AppData\\Local\\Temp/ipykernel_1440/3988302463.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepeats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m124\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m62\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m# X = X*z\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 7688 into shape (64,62,2)"
     ]
    }
   ],
   "source": [
    "# x = np.ones((64,62,2))\n",
    "y = np.array([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "# z = np.repeat(y, repeats=128, axis=0).T\n",
    "# print(z.shape)\n",
    "# z = z.reshape((64,62,2))\n",
    "\n",
    "z = np.repeat(y, repeats=124, axis=0)\n",
    "print(z.shape)\n",
    "z = z.reshape((64,62,2))\n",
    "# X = X*z\n",
    "\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "be130c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x*z\n",
    "y[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
