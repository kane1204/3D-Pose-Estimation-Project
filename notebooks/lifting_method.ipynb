{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2a29bd",
   "metadata": {},
   "source": [
    "# 2D to 3D Lifting Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc3068",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96be697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()   # interactive mode\n",
    "target_dir = \"../data/single_sungaya/\"\n",
    "out_df = pd.read_hdf(os.path.join(target_dir, \"Data_3D_Pose.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc82a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def set_axes_equal(ax):\n",
    "    # workaround, as matplotlib's 3D plot has no option for equisised axes (10/2021)\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2da8a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BugDataset(Dataset):\n",
    "    \"\"\"Bug dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, hdf_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hdf_file (string): Path to the hdf file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.bugs_frame = pd.read_hdf(hdf_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bugs_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.bugs_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        df_columns = self.bugs_frame.columns.values.tolist()\n",
    "        sample = {'image':image}\n",
    " \n",
    "        for x in range(len(df_columns)):    \n",
    "            sample[df_columns[x]] = self.bugs_frame.iloc[idx,x]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        sample_keys = list(sample.keys())\n",
    "        sample_data = list(sample.values())\n",
    "\n",
    "        dic ={'image': torch.from_numpy(image)}\n",
    "        dic[sample_keys[1]] =  sample_data[1]\n",
    "        for x in range(2,len(sample_keys)):\n",
    "            dic[sample_keys[x]] = torch.FloatTensor(sample_data[x])\n",
    "        return dic\n",
    "class Normalize(object):\n",
    "    def __init__(self,means_2, means_3, std_2, std_3):\n",
    "        self.means_2 =means_2\n",
    "        self.means_3 = means_3\n",
    "        self.std_2 = std_2\n",
    "        self.std_3 = std_3\n",
    "    def __call__(self, sample):\n",
    "        # print(\"Bruh\")\n",
    "        image = sample['image']\n",
    "        dic ={'image': image}\n",
    "        sample_keys = list(sample.keys())\n",
    "        sample_data = list(sample.values())\n",
    "\n",
    "        dic[sample_keys[1]] =  sample_data[1]\n",
    "        for x in range(2,len(sample_keys)):\n",
    "            if sample_keys[x]== 'key_points_2D':\n",
    "                dic[sample_keys[x]] = (sample_data[x]-self.means_2)/self.std_2\n",
    "            elif sample_keys[x]== 'key_points_3D':\n",
    "                dic[sample_keys[x]] = (sample_data[x]-self.means_3)/self.std_3\n",
    "            else:\n",
    "                dic[sample_keys[x]] = sample_data[x]\n",
    "        return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e318dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.read_hdf(\"../data/single_sungaya/Data_3D_Pose.hdf5\")\n",
    "array_2d = np.array(out_df['key_points_2D'].to_numpy())\n",
    "array_3d = np.array(out_df['key_points_3D'].to_numpy())\n",
    "\n",
    "for x in range(len(array_2d)):\n",
    "    array_2d[x] = np.array(array_2d[x])\n",
    "    array_3d[x] = np.array(array_3d[x])\n",
    "\n",
    "fixed_array_2d = np.empty((3778,124))\n",
    "fixed_array_3d = np.empty((3778,186))\n",
    "for x in range(len(fixed_array_2d)):\n",
    "    z = array_2d[x].reshape(1,124)\n",
    "    fixed_array_2d[x] = z\n",
    "for x in range(len(fixed_array_3d)):\n",
    "    z = array_3d[x].reshape(1,186)\n",
    "    fixed_array_3d[x] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8766073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_2d = np.mean(fixed_array_2d, axis=0).reshape((62,2))\n",
    "# print(means_2d)\n",
    "means_3d = np.mean(fixed_array_3d, axis=0).reshape((62,3))\n",
    "std_2d =  np.std(fixed_array_2d, axis=0).reshape((62,2))\n",
    "# print(std_2d)\n",
    "std_3d = np.std(fixed_array_3d, axis=0).reshape((62,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4a8ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sungaya_dataset = BugDataset(hdf_file='../data/single_sungaya/Data_3D_Pose.hdf5',\n",
    "                             root_dir=target_dir,transform=transforms.Compose([\n",
    "                                Normalize(means_2d, means_3d, std_2d, std_3d),\n",
    "                                ToTensor()\n",
    "                                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f068e49b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample = sungaya_dataset[69]\n",
    "# # print(sample)\n",
    "# image = sample[\"file_name\"]\n",
    "# plt.figure()\n",
    "# plt.imshow(io.imread(os.path.join(target_dir,image)))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b63446",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(sungaya_dataset))\n",
    "test_size = len(sungaya_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(sungaya_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5362d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "263dbf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))    \n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_inputs,hidden,n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.seq1 = nn.Sequential(\n",
    "            nn.Linear(n_inputs, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, n_inputs)\n",
    "        )\n",
    "        self.seq2 = nn.Sequential(\n",
    "            nn.Linear(n_inputs, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, n_inputs)\n",
    "        )\n",
    "        self.out = nn.Linear(n_inputs, n_output)\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        residual = x\n",
    "        out = self.seq1(x)\n",
    "        out+=residual\n",
    "        out = self.seq2(out)\n",
    "        return self.out(x)\n",
    "\n",
    "# model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b451fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        X = data['key_points_2D']\n",
    "        y = data['key_points_3D'][:,:,2]\n",
    "        X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        # print(X.shape)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "#             print(data['key_points_2D'])\n",
    "            X = data['key_points_2D']\n",
    "            y = data['key_points_3D'][:,:,2]\n",
    "            # print(y)\n",
    "            X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "            correct += (abs(pred - y)<0.72).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Accuracy: {(correct / size):>4f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54b6795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(2*62,2054,62).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "588a064a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.328298  [    0/ 3022]\n",
      "Test Error: \n",
      " Accuracy: 36.038360%, Avg loss: 1.021447 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.093633  [    0/ 3022]\n",
      "Test Error: \n",
      " Accuracy: 37.019841%, Avg loss: 0.899449 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.978459  [    0/ 3022]\n",
      "Test Error: \n",
      " Accuracy: 37.410053%, Avg loss: 0.834853 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.914169  [    0/ 3022]\n",
      "Test Error: \n",
      " Accuracy: 37.710317%, Avg loss: 0.795468 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.872570  [    0/ 3022]\n",
      "Test Error: \n",
      " Accuracy: 37.896825%, Avg loss: 0.767913 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "learning_rate =5e-3\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "983795ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9127_Img_synth.png', '9063_Img_synth.png', '7623_Img_synth.png', '7882_Img_synth.png', '2707_Img_synth.png', '8374_Img_synth.png', '3052_Img_synth.png', '3380_Img_synth.png', '915_Img_synth.png', '6107_Img_synth.png', '9772_Img_synth.png', '7974_Img_synth.png', '6039_Img_synth.png', '6945_Img_synth.png', '8339_Img_synth.png', '4155_Img_synth.png', '3102_Img_synth.png', '6229_Img_synth.png', '3155_Img_synth.png', '3321_Img_synth.png', '2247_Img_synth.png', '3077_Img_synth.png', '8608_Img_synth.png', '67_Img_synth.png', '529_Img_synth.png', '8422_Img_synth.png', '5936_Img_synth.png', '980_Img_synth.png', '8527_Img_synth.png', '9179_Img_synth.png', '2384_Img_synth.png', '2209_Img_synth.png', '91_Img_synth.png', '961_Img_synth.png', '4904_Img_synth.png', '2484_Img_synth.png', '473_Img_synth.png', '7213_Img_synth.png', '9542_Img_synth.png', '5805_Img_synth.png', '2521_Img_synth.png', '444_Img_synth.png', '7836_Img_synth.png', '7440_Img_synth.png', '8192_Img_synth.png', '9933_Img_synth.png', '2481_Img_synth.png', '8187_Img_synth.png', '7293_Img_synth.png', '3387_Img_synth.png', '3481_Img_synth.png', '3996_Img_synth.png', '9158_Img_synth.png', '5781_Img_synth.png', '7204_Img_synth.png', '5092_Img_synth.png', '4869_Img_synth.png', '8169_Img_synth.png', '5005_Img_synth.png', '8061_Img_synth.png', '9078_Img_synth.png', '5020_Img_synth.png', '9818_Img_synth.png', '9128_Img_synth.png']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        image = data['file_name']\n",
    "        print(image)\n",
    "        vis = data['visibility'].numpy()\n",
    "        X = data['key_points_2D']\n",
    "        y = data['key_points_3D']\n",
    "        # print(y)\n",
    "        X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "        pred = model(X)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97f6ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stick_bug(ax, points, simple=False):\n",
    "    limb_ranges=[[0,7],[8,14],[15,21],[22,28],[29,35],[36,42],[43,49],[53,56],[59,62]]\n",
    "    if len(points) < 62:\n",
    "        return\n",
    "    elif len(points) == 62:\n",
    "        points = np.array(points).T\n",
    "        if not simple:\n",
    "            for (fr,end) in limb_ranges:\n",
    "                ax.plot(points[0][fr:end], points[1][fr:end], points[2][fr:end])\n",
    "                ax.scatter(points[0][fr:end], points[1][fr:end], points[2][fr:end], marker='o',s=10)\n",
    "            return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6a373ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88.99670712 74.52081008 82.27856184 87.02610404 84.91326635 80.01787577\n",
      " 79.16677535 91.49770786 82.97834698 77.35048865 74.88972531 69.72560311\n",
      " 53.37564098 60.09707244 86.23143811 76.92643231 76.50429076 77.25325285\n",
      " 66.701156   63.04500856 65.02691577 86.1515509  67.93497718 63.45905058\n",
      " 70.3774278  62.94523632 63.08309975 50.33646322 84.09944551 77.4294519\n",
      " 70.0195482  77.9449803  61.04299292 54.20464402 63.37799878 73.11176568\n",
      " 74.0028501  82.5490163  80.49440179 60.88619502 52.14650169 55.53434705\n",
      " 87.69979737 68.23590313 74.23893474 84.92671601 63.33240963 53.0654008\n",
      " 55.05157213 77.91416536 82.6213757  69.0313619  75.5842984  85.37530604\n",
      " 79.62975241 59.68419893 83.31401679 89.73980452 86.81115037 95.54601976\n",
      " 57.3468095  58.25207089]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d02061ebcc542afb9422c74bb5f03c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences Point: 0 7.391285965277319\n",
      "Differences Point: 1 18.172907499561518\n",
      "Differences Point: 2 11.362536468801721\n",
      "Differences Point: 3 11.59804844223612\n",
      "Differences Point: 4 12.869372545875677\n",
      "Differences Point: 5 16.67552910612646\n",
      "Differences Point: 6 9.809581150482458\n",
      "Differences Point: 7 1.1383322253040689\n",
      "Differences Point: 8 8.37610688022707\n",
      "Differences Point: 9 12.13636676878231\n",
      "Differences Point: 10 8.350920497368818\n",
      "Differences Point: 11 8.75429311500828\n",
      "Differences Point: 12 2.3271489273548838\n",
      "Differences Point: 13 12.26295855939724\n",
      "Differences Point: 14 4.103354829112021\n",
      "Differences Point: 15 12.859166798565113\n",
      "Differences Point: 16 11.792111030028408\n",
      "Differences Point: 17 10.10620564966456\n",
      "Differences Point: 18 0.5195010089360892\n",
      "Differences Point: 19 0.6746955458844752\n",
      "Differences Point: 20 1.7570487060727515\n",
      "Differences Point: 21 5.411505899490493\n",
      "Differences Point: 22 22.739499588103357\n",
      "Differences Point: 23 26.526262736953555\n",
      "Differences Point: 24 13.589727036773596\n",
      "Differences Point: 25 8.300129261652586\n",
      "Differences Point: 26 13.733715911616002\n",
      "Differences Point: 27 3.01500627085467\n",
      "Differences Point: 28 10.320972725832547\n",
      "Differences Point: 29 14.493605800513492\n",
      "Differences Point: 30 19.49426128193076\n",
      "Differences Point: 31 3.170688189924718\n",
      "Differences Point: 32 4.8821808756283716\n",
      "Differences Point: 33 3.8669520652048988\n",
      "Differences Point: 34 14.628845778258807\n",
      "Differences Point: 35 18.045735259151684\n",
      "Differences Point: 36 15.283930861866594\n",
      "Differences Point: 37 7.170114779593803\n",
      "Differences Point: 38 10.313687743586016\n",
      "Differences Point: 39 7.934377163647014\n",
      "Differences Point: 40 12.35534420577848\n",
      "Differences Point: 41 6.512504751742888\n",
      "Differences Point: 42 3.9000866420059452\n",
      "Differences Point: 43 21.2369356247779\n",
      "Differences Point: 44 14.268954657161885\n",
      "Differences Point: 45 2.438327905829439\n",
      "Differences Point: 46 7.545982527702002\n",
      "Differences Point: 47 5.777223920513606\n",
      "Differences Point: 48 10.805237959308648\n",
      "Differences Point: 49 16.506252734754725\n",
      "Differences Point: 50 11.291121945399041\n",
      "Differences Point: 51 20.763522420338262\n",
      "Differences Point: 52 20.327046682503678\n",
      "Differences Point: 53 17.52837194129789\n",
      "Differences Point: 54 19.852683309112635\n",
      "Differences Point: 55 30.334012560163565\n",
      "Differences Point: 56 10.59848122349301\n",
      "Differences Point: 57 0.44845360719317284\n",
      "Differences Point: 58 9.530998402358193\n",
      "Differences Point: 59 6.615112755142718\n",
      "Differences Point: 60 32.329062118452754\n",
      "Differences Point: 61 17.963870062349223\n"
     ]
    }
   ],
   "source": [
    "sample = 59\n",
    "\n",
    "prediction = (pred[sample].cpu()).numpy()\n",
    "actual = (y[sample].cpu()).numpy()\n",
    "\n",
    "\n",
    "mean = means_3d[:,2]\n",
    "std = std_3d[:,2]\n",
    "\n",
    "unnormalised_est = (prediction*std)+mean\n",
    "unnormalised_acc = (actual*std_3d)+means_3d\n",
    "# print(unnormalised_est)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "for i in range(len(unnormalised_acc)):\n",
    "    # ax.scatter(unnormalised_acc[i,0], unnormalised_acc[i,1], unnormalised_acc[i,2], marker='o',s=10)\n",
    "    ax.scatter(unnormalised_acc[i,0], unnormalised_acc[i,1], unnormalised_est[i], marker='x',s=10)\n",
    "    print(\"Differences Point:\", i, np.abs(unnormalised_acc[i,2]-unnormalised_est[i]))\n",
    "\n",
    "plot_stick_bug(ax, unnormalised_acc)\n",
    "\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "ax.set_zlabel('Z axis')\n",
    "\n",
    "# use custom function to ensure equal axis proportions\n",
    "set_axes_equal(ax)\n",
    "\n",
    "# opens external plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28631d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7119054123466448"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(50-mean[0])/std[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
