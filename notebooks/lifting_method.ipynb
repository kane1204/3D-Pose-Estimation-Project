{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2a29bd",
   "metadata": {},
   "source": [
    "# 2D to 3D Lifting Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc3068",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96be697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()   # interactive mode\n",
    "target_dir = \"../data/single_sungaya/\"\n",
    "out_df = pd.read_hdf(os.path.join(target_dir, \"Data_3D_Pose.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc82a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def set_axes_equal(ax):\n",
    "    # workaround, as matplotlib's 3D plot has no option for equisised axes (10/2021)\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2da8a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BugDataset(Dataset):\n",
    "    \"\"\"Bug dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, hdf_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hdf_file (string): Path to the hdf file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.bugs_frame = pd.read_hdf(hdf_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bugs_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.bugs_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        df_columns = self.bugs_frame.columns.values.tolist()\n",
    "        sample = {'image':image}\n",
    " \n",
    "        for x in range(len(df_columns)):    \n",
    "            sample[df_columns[x]] = self.bugs_frame.iloc[idx,x]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        sample_keys = list(sample.keys())\n",
    "        sample_data = list(sample.values())\n",
    "\n",
    "        dic ={'image': torch.from_numpy(image)}\n",
    "        dic[sample_keys[1]] =  sample_data[1]\n",
    "        for x in range(2,len(sample_keys)):\n",
    "            dic[sample_keys[x]] = torch.FloatTensor(sample_data[x])\n",
    "        return dic\n",
    "class Normalize(object):\n",
    "    def __init__(self,means_2, means_3, std_2, std_3):\n",
    "        self.means_2 =means_2\n",
    "        self.means_3 = means_3\n",
    "        self.std_2 = std_2\n",
    "        self.std_3 = std_3\n",
    "    def __call__(self, sample):\n",
    "        # print(\"Bruh\")\n",
    "        image = sample['image']\n",
    "        dic ={'image': image}\n",
    "        sample_keys = list(sample.keys())\n",
    "        sample_data = list(sample.values())\n",
    "\n",
    "        dic[sample_keys[1]] =  sample_data[1]\n",
    "        for x in range(2,len(sample_keys)):\n",
    "            if sample_keys[x]== 'key_points_2D':\n",
    "                dic[sample_keys[x]] = (sample_data[x]-self.means_2)/self.std_2\n",
    "            elif sample_keys[x]== 'key_points_3D':\n",
    "                dic[sample_keys[x]] = (sample_data[x]-self.means_3)/self.std_3\n",
    "            else:\n",
    "                dic[sample_keys[x]] = sample_data[x]\n",
    "        return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e318dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.read_hdf(\"../data/single_sungaya/Data_3D_Pose.hdf5\")\n",
    "array_2d = np.array(out_df['key_points_2D'].to_numpy())\n",
    "array_3d = np.array(out_df['key_points_3D'].to_numpy())\n",
    "\n",
    "for x in range(len(array_2d)):\n",
    "    array_2d[x] = np.array(array_2d[x])\n",
    "    array_3d[x] = np.array(array_3d[x])\n",
    "\n",
    "fixed_array_2d = np.empty((3778,124))\n",
    "fixed_array_3d = np.empty((3778,186))\n",
    "for x in range(len(fixed_array_2d)):\n",
    "    z = array_2d[x].reshape(1,124)\n",
    "    fixed_array_2d[x] = z\n",
    "for x in range(len(fixed_array_3d)):\n",
    "    z = array_3d[x].reshape(1,186)\n",
    "    fixed_array_3d[x] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8766073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_2d = np.mean(fixed_array_2d, axis=0).reshape((62,2))\n",
    "# print(means_2d)\n",
    "means_3d = np.mean(fixed_array_3d, axis=0).reshape((62,3))\n",
    "std_2d =  np.std(fixed_array_2d, axis=0).reshape((62,2))\n",
    "# print(std_2d)\n",
    "std_3d = np.std(fixed_array_3d, axis=0).reshape((62,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4a8ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sungaya_dataset = BugDataset(hdf_file='../data/single_sungaya/Data_3D_Pose.hdf5',\n",
    "                             root_dir=target_dir,transform=transforms.Compose([\n",
    "                                Normalize(means_2d, means_3d, std_2d, std_3d),\n",
    "                                ToTensor()\n",
    "                                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f068e49b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample = sungaya_dataset[69]\n",
    "# # print(sample)\n",
    "# image = sample[\"file_name\"]\n",
    "# plt.figure()\n",
    "# plt.imshow(io.imread(os.path.join(target_dir,image)))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b63446",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(sungaya_dataset))\n",
    "test_size = len(sungaya_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(sungaya_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5362d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "263dbf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))    \n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_inputs,hidden,n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.seq1 = nn.Sequential(\n",
    "            nn.Linear(n_inputs, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, n_inputs)\n",
    "        )\n",
    "        self.seq2 = nn.Sequential(\n",
    "            nn.Linear(n_inputs, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, n_inputs)\n",
    "        )\n",
    "        self.out = nn.Linear(n_inputs, n_output)\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        residual = x\n",
    "        out = self.seq1(x)\n",
    "        out+=residual\n",
    "        out = self.seq2(out)\n",
    "        return self.out(x)\n",
    "\n",
    "# model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b451fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        X = data['key_points_2D']\n",
    "        y = data['key_points_3D'][:,:,2]\n",
    "        X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        # print(X.shape)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "#             print(data['key_points_2D'])\n",
    "            X = data['key_points_2D']\n",
    "            y = data['key_points_3D'][:,:,2]\n",
    "            # print(y)\n",
    "            X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "            correct += (abs(pred - y)<0.72).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Accuracy: {(correct / size):>4f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54b6795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(2*62,2054,62).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "588a064a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.262971  [    0/ 3022]\n",
      "Test Error: \n",
      " Accuracy: 36.152116%, Avg loss: 1.077434 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.990087  [    0/ 3022]\n",
      "Test Error: \n",
      " Accuracy: 36.849206%, Avg loss: 0.945300 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.859393  [    0/ 3022]\n",
      "Test Error: \n",
      " Accuracy: 36.944444%, Avg loss: 0.876640 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.789849  [    0/ 3022]\n",
      "Test Error: \n",
      " Accuracy: 37.013228%, Avg loss: 0.835487 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.747714  [    0/ 3022]\n",
      "Test Error: \n",
      " Accuracy: 37.060847%, Avg loss: 0.807008 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "learning_rate =5e-3\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "983795ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        image = data['file_name']\n",
    "        vis = data['visibility'].numpy()\n",
    "        X = data['key_points_2D']\n",
    "        y = data['key_points_3D'][:,:]\n",
    "        # print(y)\n",
    "        X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "        pred = model(X)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6a373ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1940f4f0c8064944b1ca74c601af063f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences Point: 0 57.43191099039723\n",
      "Differences Point: 1 54.6997440457053\n",
      "Differences Point: 2 62.24463324241469\n",
      "Differences Point: 3 59.67763263495863\n",
      "Differences Point: 4 73.37854469676313\n",
      "Differences Point: 5 66.32940541538028\n",
      "Differences Point: 6 86.96508008574165\n",
      "Differences Point: 7 40.174528302985436\n",
      "Differences Point: 8 35.146164939026676\n",
      "Differences Point: 9 30.909898729951692\n",
      "Differences Point: 10 41.49290934000783\n",
      "Differences Point: 11 0.16751373171109663\n",
      "Differences Point: 12 4.223510102144928\n",
      "Differences Point: 13 0.40343176919282087\n",
      "Differences Point: 14 44.04270168930361\n",
      "Differences Point: 15 67.14620829448495\n",
      "Differences Point: 16 64.01719544410889\n",
      "Differences Point: 17 36.985643354459626\n",
      "Differences Point: 18 12.54230441672371\n",
      "Differences Point: 19 28.683385121230685\n",
      "Differences Point: 20 26.060109161199307\n",
      "Differences Point: 21 58.024008677706206\n",
      "Differences Point: 22 67.58103875488905\n",
      "Differences Point: 23 53.32085536508248\n",
      "Differences Point: 24 51.81436854066351\n",
      "Differences Point: 25 62.016908380378254\n",
      "Differences Point: 26 51.18828467803928\n",
      "Differences Point: 27 14.938314876600998\n",
      "Differences Point: 28 45.307910062496376\n",
      "Differences Point: 29 42.58170712862011\n",
      "Differences Point: 30 22.69753984132194\n",
      "Differences Point: 31 47.715252151245295\n",
      "Differences Point: 32 39.98895297454942\n",
      "Differences Point: 33 45.851973016881175\n",
      "Differences Point: 34 14.665446084693258\n",
      "Differences Point: 35 40.48557427386186\n",
      "Differences Point: 36 21.658934326419512\n",
      "Differences Point: 37 33.93805152368077\n",
      "Differences Point: 38 37.858355824841055\n",
      "Differences Point: 39 37.61395830969286\n",
      "Differences Point: 40 47.71377215837856\n",
      "Differences Point: 41 13.709792159683047\n",
      "Differences Point: 42 55.97704223562641\n",
      "Differences Point: 43 62.8354897649192\n",
      "Differences Point: 44 53.26020366683588\n",
      "Differences Point: 45 68.3022125862608\n",
      "Differences Point: 46 40.63308441893628\n",
      "Differences Point: 47 37.62061912929744\n",
      "Differences Point: 48 47.831068540325305\n",
      "Differences Point: 49 35.87157807975973\n",
      "Differences Point: 50 18.7702103145416\n",
      "Differences Point: 51 48.61963729308036\n",
      "Differences Point: 52 35.713630584898056\n",
      "Differences Point: 53 36.54447319482324\n",
      "Differences Point: 54 56.670130655397315\n",
      "Differences Point: 55 49.4420870843951\n",
      "Differences Point: 56 23.165362954807733\n",
      "Differences Point: 57 49.0314614268691\n",
      "Differences Point: 58 43.528356501883536\n",
      "Differences Point: 59 57.154760292246465\n",
      "Differences Point: 60 57.55447664521262\n",
      "Differences Point: 61 65.80433241095852\n"
     ]
    }
   ],
   "source": [
    "sample = 1\n",
    "prediction = pred[sample].cpu()\n",
    "ac = y[sample].cpu()\n",
    "est = prediction.numpy()\n",
    "actual = ac.numpy()\n",
    "\n",
    "mean = means_3d[:,2]\n",
    "std = std_3d[:,2]\n",
    "\n",
    "unnormalised_est = (est+mean)*std\n",
    "unnormalised_acc = (actual+means_3d)*std_3d\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "for i in range(len(unnormalised_acc)):\n",
    "    ax.scatter(unnormalised_acc[i,0], unnormalised_acc[i,1], unnormalised_acc[i,2], marker='o',s=10)\n",
    "    ax.scatter(unnormalised_acc[i,0], unnormalised_acc[i,1], unnormalised_est[i], marker='x',s=10)\n",
    "    print(\"Differences Point:\", i, np.abs(unnormalised_acc[i,2]-unnormalised_est[i]))\n",
    "\n",
    "\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "ax.set_zlabel('Z axis')\n",
    "\n",
    "# use custom function to ensure equal axis proportions\n",
    "set_axes_equal(ax)\n",
    "\n",
    "# opens external plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28631d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7119054123466448"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(50-mean[0])/std[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
