{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2a29bd",
   "metadata": {},
   "source": [
    "# 2D to 3D Lifting Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc3068",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "96be697e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x247a763d1c0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc82a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def set_axes_equal(ax):\n",
    "    # workaround, as matplotlib's 3D plot has no option for equisised axes (10/2021)\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2da8a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BugDataset(Dataset):\n",
    "    \"\"\"Bug dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hdf_file (string): Path to the hdf file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.bugs_frame = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bugs_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.bugs_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        df_columns = self.bugs_frame.columns.values.tolist()\n",
    "        sample = {'image':image}\n",
    " \n",
    "        for x in range(len(df_columns)):    \n",
    "            sample[df_columns[x]] = self.bugs_frame.iloc[idx,x]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        sample_keys = list(sample.keys())\n",
    "        sample_data = list(sample.values())\n",
    "\n",
    "        dic ={'image': torch.from_numpy(image)}\n",
    "        dic[sample_keys[1]] =  sample_data[1]\n",
    "        for x in range(2,len(sample_keys)):\n",
    "            dic[sample_keys[x]] = torch.FloatTensor(sample_data[x])\n",
    "        return dic\n",
    "class Normalize(object):\n",
    "    def __init__(self,means_2, means_3, std_2, std_3):\n",
    "        self.means_2 =means_2\n",
    "        self.means_3 = means_3\n",
    "        self.std_2 = std_2\n",
    "        self.std_3 = std_3\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "        dic ={'image': image}\n",
    "        sample_keys = list(sample.keys())\n",
    "        sample_data = list(sample.values())\n",
    "\n",
    "        dic[sample_keys[1]] =  sample_data[1]\n",
    "        for x in range(2,len(sample_keys)):\n",
    "            if sample_keys[x]== 'key_points_2D':\n",
    "                dic[sample_keys[x]] = (sample_data[x]-self.means_2)/self.std_2\n",
    "            elif sample_keys[x]== 'key_points_3D':\n",
    "                dic[sample_keys[x]] = (sample_data[x]-self.means_3)/self.std_3\n",
    "            else:\n",
    "                dic[sample_keys[x]] = sample_data[x]\n",
    "        return dic\n",
    "\n",
    "class Centralize(object):\n",
    "    def __init__(self, keypoint=3):\n",
    "        self.center_keypoint = keypoint\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "        dic ={'image': image}\n",
    "        sample_keys = list(sample.keys())\n",
    "        sample_data = list(sample.values())\n",
    "\n",
    "        dic[sample_keys[1]] =  sample_data[1]\n",
    "        for x in range(2,len(sample_keys)):\n",
    "            if sample_keys[x]== 'key_points_2D':\n",
    "                x_diff,y_diff = sample_data[x][self.center_keypoint-1][0],sample_data[x][self.center_keypoint-1][1]\n",
    "                # print(x_diff,y_diff)\n",
    "                # print(\"2D Init\",sample_data[x][0])\n",
    "                for i in range(len(sample_data[x])):\n",
    "                    sample_data[x][i][0] = sample_data[x][i][0] - x_diff\n",
    "                    sample_data[x][i][1] = sample_data[x][i][1] - y_diff\n",
    "                # print(\"2D Out\", sample_data[x][0])\n",
    "                dic[sample_keys[x]] = sample_data[x]\n",
    "\n",
    "            elif sample_keys[x]== 'key_points_3D':\n",
    "                x_diff,y_diff,z_diff = sample_data[x][self.center_keypoint-1][0],sample_data[x][self.center_keypoint-1][1],sample_data[x][self.center_keypoint-1][2]\n",
    "                # print(x_diff,y_diff, z_diff)\n",
    "                # print(\"3D Init\",sample_data[x][0])\n",
    "                for i in range(len(sample_data[x])):\n",
    "                    sample_data[x][i][0] = sample_data[x][i][0] - x_diff\n",
    "                    sample_data[x][i][1] = sample_data[x][i][1] - y_diff\n",
    "                    sample_data[x][i][2] = sample_data[x][i][2] - z_diff\n",
    "                # print(\"3D Out\", sample_data[x][0])\n",
    "                dic[sample_keys[x]] = sample_data[x]\n",
    "            else:\n",
    "                dic[sample_keys[x]] = sample_data[x]\n",
    "        return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0c44946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"../data/single_sungaya/\"\n",
    "out_df = pd.read_hdf(os.path.join(target_dir, \"Data_3D_Pose.hdf5\"))\n",
    "new_df = pd.DataFrame()\n",
    "for col, x in out_df.iterrows():\n",
    "    if x['visibility'][2]==1:\n",
    "        new_df = new_df.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e318dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_2d = np.array(new_df['key_points_2D'].to_numpy())\n",
    "array_3d = np.array(new_df['key_points_3D'].to_numpy())\n",
    "\n",
    "for x in range(len(array_2d)):\n",
    "    array_2d[x] = np.array(array_2d[x])\n",
    "    array_3d[x] = np.array(array_3d[x])\n",
    "\n",
    "fixed_array_2d = np.empty((len(array_2d),124))\n",
    "fixed_array_3d = np.empty((len(array_3d),186))\n",
    "for x in range(len(fixed_array_2d)):\n",
    "    z = array_2d[x].reshape(1,124)\n",
    "    fixed_array_2d[x] = z\n",
    "for x in range(len(fixed_array_3d)):\n",
    "    z = array_3d[x].reshape(1,186)\n",
    "    fixed_array_3d[x] = z\n",
    "\n",
    "means_2d = np.mean(fixed_array_2d, axis=0).reshape((62,2))\n",
    "\n",
    "means_3d = np.mean(fixed_array_3d, axis=0).reshape((62,3))\n",
    "std_2d =  np.std(fixed_array_2d, axis=0).reshape((62,2))\n",
    "\n",
    "std_3d = np.std(fixed_array_3d, axis=0).reshape((62,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4a8ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sungaya_dataset = BugDataset(df=new_df,\n",
    "                             root_dir=target_dir,transform=transforms.Compose([\n",
    "                                Centralize(),\n",
    "                                Normalize(means_2d, means_3d, std_2d, std_3d),\n",
    "                                ToTensor()\n",
    "                                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f068e49b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263c42d969254fc88a1418ff8903a363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = sungaya_dataset[1]\n",
    "# print(sample)\n",
    "image = sample[\"file_name\"]\n",
    "plt.figure()\n",
    "plt.imshow(io.imread(os.path.join(target_dir,image)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "02b63446",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(sungaya_dataset))\n",
    "test_size = len(sungaya_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(sungaya_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5362d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "263dbf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))    \n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_inputs,hidden,n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.seq1 = nn.Sequential(\n",
    "            nn.Linear(n_inputs, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, n_inputs)\n",
    "        )\n",
    "        self.seq2 = nn.Sequential(\n",
    "            nn.Linear(n_inputs, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, n_inputs)\n",
    "        )\n",
    "        self.out = nn.Linear(n_inputs, n_output)\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        residual = x\n",
    "        out = self.seq1(x)\n",
    "        out+=residual\n",
    "        out = self.seq2(out)\n",
    "        return self.out(x)\n",
    "\n",
    "# model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5b451fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        X = data['key_points_2D']\n",
    "        y = data['key_points_3D'][:,:,2]\n",
    "        X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        # print(X.shape)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "#             print(data['key_points_2D'])\n",
    "            X = data['key_points_2D']\n",
    "            y = data['key_points_3D'][:,:,2]\n",
    "            # print(y)\n",
    "            X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "            correct += (abs(pred - y)<0.72).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Accuracy: {(correct / size):>4f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "54b6795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(2*62,2054,62).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "588a064a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 4421144987204023517970432.000000  [    0/ 2612]\n",
      "Test Error: \n",
      " Accuracy: 37.585627%, Avg loss: 105427526430778252591104.000000 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 82560952139276189958144.000000  [    0/ 2612]\n",
      "Test Error: \n",
      " Accuracy: 39.561162%, Avg loss: 92196403132617222782976.000000 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 62472591958194564104192.000000  [    0/ 2612]\n",
      "Test Error: \n",
      " Accuracy: 40.056575%, Avg loss: 85594101513803188404224.000000 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 56061952075813286313984.000000  [    0/ 2612]\n",
      "Test Error: \n",
      " Accuracy: 40.567278%, Avg loss: 79875874516240508649472.000000 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 50749357336579346006016.000000  [    0/ 2612]\n",
      "Test Error: \n",
      " Accuracy: 41.032110%, Avg loss: 74859165044270363049984.000000 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "learning_rate =5e-3\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "983795ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1370_Img_synth.png\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        image = data['file_name']\n",
    "        print(image)\n",
    "        vis = data['visibility'].numpy()\n",
    "        X = data['key_points_2D']\n",
    "        y = data['key_points_3D']\n",
    "        # print(y)\n",
    "        X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "        pred = model(X)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "97f6ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stick_bug(ax, points, simple=False):\n",
    "    limb_ranges=[[0,7],[8,14],[15,21],[22,28],[29,35],[36,42],[43,49],[53,56],[59,62]]\n",
    "    if len(points) < 62:\n",
    "        return\n",
    "    elif len(points) == 62:\n",
    "        points = np.array(points).T\n",
    "        if not simple:\n",
    "            for (fr,end) in limb_ranges:\n",
    "                ax.plot(points[0][fr:end], points[1][fr:end], points[2][fr:end])\n",
    "                ax.scatter(points[0][fr:end], points[1][fr:end], points[2][fr:end], marker='o',s=10)\n",
    "            return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e6a373ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3274_Img_synth.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b84472b736b4ff3a44a2d63d1cdd0e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = 59\n",
    "print(image[sample])\n",
    "prediction = (pred[sample].cpu()).numpy()\n",
    "actual = (y[sample].cpu()).numpy()\n",
    "\n",
    "\n",
    "mean = means_3d[:,2]\n",
    "std = std_3d[:,2]\n",
    "\n",
    "unnormalised_est = (prediction*std)+mean\n",
    "unnormalised_acc = (actual*std_3d)+means_3d\n",
    "# print(unnormalised_est)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "for i in range(len(unnormalised_acc)):\n",
    "    # ax.scatter(unnormalised_acc[i,0], unnormalised_acc[i,1], unnormalised_acc[i,2], marker='o',s=10)\n",
    "    ax.scatter(unnormalised_acc[i,0], unnormalised_acc[i,1], unnormalised_est[i], marker='x',s=10)\n",
    "    # print(\"Differences Point:\", i, np.abs(unnormalised_acc[i,2]-unnormalised_est[i]))\n",
    "\n",
    "plot_stick_bug(ax, unnormalised_acc)\n",
    "\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "ax.set_zlabel('Z axis')\n",
    "\n",
    "# use custom function to ensure equal axis proportions\n",
    "set_axes_equal(ax)\n",
    "\n",
    "# opens external plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "28631d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.2019235329074087"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(50-mean[0])/std[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
