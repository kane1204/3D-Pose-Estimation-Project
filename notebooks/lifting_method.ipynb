{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c2a29bd",
   "metadata": {},
   "source": [
    "# 2D to 3D Lifting Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cc3068",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96be697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()   # interactive mode\n",
    "target_dir = \"../data/single_sungaya/\"\n",
    "out_df = pd.read_hdf(os.path.join(target_dir, \"Data_3D_Pose.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc82a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def set_axes_equal(ax):\n",
    "    # workaround, as matplotlib's 3D plot has no option for equisised axes (10/2021)\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2da8a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BugDataset(Dataset):\n",
    "    \"\"\"Bug dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, hdf_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hdf_file (string): Path to the hdf file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.bugs_frame = pd.read_hdf(hdf_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.bugs_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.bugs_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        df_columns = self.bugs_frame.columns.values.tolist()\n",
    "        sample = {'image':image}\n",
    " \n",
    "        for x in range(len(df_columns)):    \n",
    "            sample[df_columns[x]] = self.bugs_frame.iloc[idx,x]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        sample_keys = list(sample.keys())\n",
    "        sample_data = list(sample.values())\n",
    "\n",
    "        dic ={'image': torch.from_numpy(image)}\n",
    "        dic[sample_keys[1]] =  sample_data[1]\n",
    "        for x in range(2,len(sample_keys)):\n",
    "            dic[sample_keys[x]] = torch.FloatTensor(sample_data[x])\n",
    "        return dic\n",
    "class Normalize(object):\n",
    "    def __init__(self,means_2, means_3, std_2, std_3):\n",
    "        self.means_2 =means_2\n",
    "        self.means_3 = means_3\n",
    "        self.std_2 = std_2\n",
    "        self.std_3 = std_3\n",
    "    def __call__(self, sample):\n",
    "        # print(\"Bruh\")\n",
    "        image = sample['image']\n",
    "        dic ={'image': image}\n",
    "        sample_keys = list(sample.keys())\n",
    "        sample_data = list(sample.values())\n",
    "\n",
    "        dic[sample_keys[1]] =  sample_data[1]\n",
    "        for x in range(2,len(sample_keys)):\n",
    "            if sample_keys[x]== 'key_points_2D':\n",
    "                dic[sample_keys[x]] = (sample_data[x]-self.means_2)/self.std_2\n",
    "            elif sample_keys[x]== 'key_points_3D':\n",
    "                dic[sample_keys[x]] = (sample_data[x]-self.means_3)/self.std_3\n",
    "            else:\n",
    "                dic[sample_keys[x]] = sample_data[x]\n",
    "        return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e318dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.read_hdf(\"../data/single_sungaya/Data_3D_Pose.hdf5\")\n",
    "array_2d = np.array(out_df['key_points_2D'].to_numpy())\n",
    "array_3d = np.array(out_df['key_points_3D'].to_numpy())\n",
    "\n",
    "for x in range(len(array_2d)):\n",
    "    array_2d[x] = np.array(array_2d[x])\n",
    "    array_3d[x] = np.array(array_3d[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3f8935",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_array_2d = np.empty((3778,124))\n",
    "fixed_array_3d = np.empty((3778,186))\n",
    "for x in range(len(fixed_array_2d)):\n",
    "    z = array_2d[x].reshape(1,124)\n",
    "    fixed_array_2d[x] = z\n",
    "for x in range(len(fixed_array_3d)):\n",
    "    z = array_3d[x].reshape(1,186)\n",
    "    fixed_array_3d[x] = z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8766073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "means_2d = np.mean(fixed_array_2d, axis=0).reshape((62,2))\n",
    "# print(means_2d)\n",
    "means_3d = np.mean(fixed_array_3d, axis=0).reshape((62,3))\n",
    "std_2d =  np.std(fixed_array_2d, axis=0).reshape((62,2))\n",
    "# print(std_2d)\n",
    "std_3d = np.std(fixed_array_3d, axis=0).reshape((62,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4a8ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sungaya_dataset = BugDataset(hdf_file='../data/single_sungaya/Data_3D_Pose.hdf5',\n",
    "                             root_dir=target_dir,transform=transforms.Compose([\n",
    "                                Normalize(means_2d, means_3d, std_2d, std_3d),\n",
    "                                ToTensor()\n",
    "                                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85d25c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8686,  0.6842],\n",
       "        [-0.8116,  0.4713],\n",
       "        [-0.7497,  0.2839],\n",
       "        [-0.5250,  0.0509],\n",
       "        [-0.3587, -0.0988],\n",
       "        [-0.1519, -0.2003],\n",
       "        [ 0.0839, -0.2949],\n",
       "        [-0.8656,  0.5973],\n",
       "        [-0.8770,  0.5889],\n",
       "        [-0.8927,  0.5843],\n",
       "        [-1.0051,  0.4992],\n",
       "        [-0.9195,  0.4978],\n",
       "        [-0.8637,  0.5105],\n",
       "        [-0.8301,  0.5497],\n",
       "        [-0.7952,  0.2831],\n",
       "        [-0.8161,  0.2482],\n",
       "        [-0.8308,  0.1988],\n",
       "        [-0.9168, -0.0765],\n",
       "        [-0.8822, -0.2424],\n",
       "        [-0.8526, -0.3063],\n",
       "        [-0.8439, -0.3324],\n",
       "        [-0.7089,  0.1457],\n",
       "        [-0.7293,  0.0777],\n",
       "        [-0.7284,  0.0457],\n",
       "        [-0.6971, -0.0580],\n",
       "        [-0.6021, -0.5537],\n",
       "        [-0.5735, -0.6162],\n",
       "        [-0.5761, -0.6448],\n",
       "        [-0.8319,  0.3237],\n",
       "        [-0.7943,  0.6819],\n",
       "        [-0.7348,  0.7465],\n",
       "        [-0.5272,  0.9594],\n",
       "        [-0.3697,  1.1239],\n",
       "        [-0.2959,  1.2255],\n",
       "        [-0.2571,  1.3187],\n",
       "        [-0.7424,  0.3871],\n",
       "        [-0.7127,  0.4394],\n",
       "        [-0.7001,  0.4898],\n",
       "        [-0.6342,  0.8355],\n",
       "        [-0.4892,  1.0264],\n",
       "        [-0.4227,  1.1257],\n",
       "        [-0.3606,  1.1912],\n",
       "        [-0.6814,  0.2282],\n",
       "        [-0.6034,  0.2760],\n",
       "        [-0.5775,  0.2840],\n",
       "        [-0.0713,  0.5006],\n",
       "        [ 0.0659,  0.3199],\n",
       "        [ 0.2774,  0.3341],\n",
       "        [ 0.3647,  0.3602],\n",
       "        [-0.7532,  0.4414],\n",
       "        [-0.8382,  0.7349],\n",
       "        [-0.8310,  0.7615],\n",
       "        [-0.8628,  0.7876],\n",
       "        [-0.8835,  0.8953],\n",
       "        [-0.8197,  1.1423],\n",
       "        [-0.7669,  1.1439],\n",
       "        [-0.8382,  0.7349],\n",
       "        [-0.7883,  0.8223],\n",
       "        [-0.8210,  0.8510],\n",
       "        [-0.7928,  1.0489],\n",
       "        [-0.5830,  1.4096],\n",
       "        [-0.4393,  1.5057]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sungaya_dataset[0]['key_points_2D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f068e49b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25bbe003e99b4caba599a80b1d764202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = sungaya_dataset[69]\n",
    "# print(sample)\n",
    "image = sample[\"file_name\"]\n",
    "plt.figure()\n",
    "plt.imshow(io.imread(os.path.join(target_dir,image)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b63446",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(sungaya_dataset))\n",
    "test_size = len(sungaya_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(sungaya_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5362d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "263dbf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))    \n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_inputs,hidden,n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.seq1 = nn.Sequential(\n",
    "            nn.Linear(n_inputs, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, n_inputs)\n",
    "        )\n",
    "        self.seq2 = nn.Sequential(\n",
    "            nn.Linear(n_inputs, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, hidden),\n",
    "            nn.BatchNorm1d(hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden, n_inputs)\n",
    "        )\n",
    "        self.out = nn.Linear(n_inputs, n_output)\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        residual = x\n",
    "        out = self.seq1(x)\n",
    "        out+=residual\n",
    "        out = self.seq2(out)\n",
    "        return self.out(x)\n",
    "\n",
    "# model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b451fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        X = data['key_points_2D']\n",
    "        y = data['key_points_3D'][:,:,2]\n",
    "        X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        # print(X.shape)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "#             print(data['key_points_2D'])\n",
    "            X = data['key_points_2D']\n",
    "            y = data['key_points_3D'][:,:,2]\n",
    "            # print(y)\n",
    "            X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "            correct += ((pred - y)<0.5).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Accuracy: {(correct / size):>4f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54b6795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(2*62,2054,62).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "588a064a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.248463  [    0/ 3022]\n",
      "Test Error: \n",
      " Accuracy: 47.753968%, Avg loss: 1.082474 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.007658  [    0/ 3022]\n",
      "Test Error: \n",
      " Accuracy: 47.525132%, Avg loss: 0.963525 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.893908  [    0/ 3022]\n",
      "Test Error: \n",
      " Accuracy: 47.280423%, Avg loss: 0.898430 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.833379  [    0/ 3022]\n",
      "Test Error: \n",
      " Accuracy: 47.038360%, Avg loss: 0.857482 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.795956  [    0/ 3022]\n",
      "Test Error: \n",
      " Accuracy: 46.928571%, Avg loss: 0.828204 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "learning_rate =5e-3\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "983795ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        image = data['file_name']\n",
    "        vis = data['visibility'].numpy()\n",
    "        X = data['key_points_2D']\n",
    "        y = data['key_points_3D'][:,:]\n",
    "        # print(y)\n",
    "        X, y = X.to(device, dtype=torch.float), y.to(device, dtype=torch.float)\n",
    "        pred = model(X)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6a373ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c145bfd4a74039a13a1cd0b55a6efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = 1\n",
    "prediction = pred[sample].cpu()\n",
    "ac = y[sample].cpu()\n",
    "est = prediction.numpy()\n",
    "actual = ac.numpy()\n",
    "\n",
    "mean = means_3d[:,2]\n",
    "std = std_3d[:,2]\n",
    "\n",
    "unnormalised_est = (est+mean)*std\n",
    "unnormalised_acc = (actual+means_3d)*std_3d\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "for i in range(len(unnormalised_acc)):\n",
    "    ax.scatter(unnormalised_acc[i,0], unnormalised_acc[i,1], unnormalised_acc[i,2], marker='o',s=10)\n",
    "    ax.scatter(unnormalised_acc[i,0], unnormalised_acc[i,1], unnormalised_est[i], marker='x',s=10)\n",
    "\n",
    "\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "ax.set_zlabel('Z axis')\n",
    "\n",
    "# use custom function to ensure equal axis proportions\n",
    "set_axes_equal(ax)\n",
    "\n",
    "# opens external plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
