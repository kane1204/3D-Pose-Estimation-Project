{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2-Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from src.models.simple_3d_model import LinearModel\n",
    "from src.models.pose_resnet import BasicBlock, PoseResNet, Bottleneck\n",
    "import src.bug_dataset\n",
    "from src.eval.accuracies import keypoint_depth_pck, get_max_preds\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Code\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_stick_bug(ax, points, vis, prediction=False):\n",
    "    limb_ranges=[[0,7],[8,14],[15,21],[22,28],[29,35],[36,42],[43,49],[53,56],[59,62]]\n",
    "    reduced_limb_ranges = [[0,4],[4,7],[7,10],[10,13],[13,16],[16,19],[19,22],[22,25],[25,28]]\n",
    "    if len(points) == 62:\n",
    "        points = np.array(points).T\n",
    "        for num in range(len(limb_ranges)):\n",
    "            visible_limb = []\n",
    "            for x in range(limb_ranges[num][0],limb_ranges[num][1]):\n",
    "                if vis[x]== 1:\n",
    "                    visible_limb.append(x) \n",
    "            if prediction:\n",
    "                line, = ax.plot(points[0][visible_limb], points[1][visible_limb], points[2][visible_limb],'--', alpha=0.7, label='Prediction', color='red')\n",
    "                ax.scatter(points[0][visible_limb], points[1][visible_limb], points[2][visible_limb], marker='X',s=10, color='red')\n",
    "            else:\n",
    "                line, = ax.plot(points[0][visible_limb], points[1][visible_limb], points[2][visible_limb], label='Actual', color='blue')\n",
    "                ax.scatter(points[0][visible_limb], points[1][visible_limb], points[2][visible_limb], marker='o',s=4, color='blue')\n",
    "        return ax, line\n",
    "    elif len(points) == 28:\n",
    "        points = np.array(points).T\n",
    "        for num in range(len(reduced_limb_ranges)):\n",
    "            visible_limb = []\n",
    "            for x in range(reduced_limb_ranges[num][0],reduced_limb_ranges[num][1]):\n",
    "                if vis[x]== 1:\n",
    "                    visible_limb.append(x) \n",
    "            if prediction:\n",
    "                line, = ax.plot(points[0][visible_limb], points[1][visible_limb], points[2][visible_limb],'--', alpha=0.7, label='Prediction', color='red')\n",
    "                ax.scatter(points[0][visible_limb], points[1][visible_limb], points[2][visible_limb], marker='X',s=10, color='red')\n",
    "            else:\n",
    "                line, = ax.plot(points[0][visible_limb], points[1][visible_limb], points[2][visible_limb], label='Actual', color='blue')\n",
    "                ax.scatter(points[0][visible_limb], points[1][visible_limb], points[2][visible_limb], marker='o',s=4, color='blue')\n",
    "        return ax, line\n",
    "\n",
    "def set_axes_equal(ax):\n",
    "    # workaround, as matplotlib's 3D plot has no option for equisised axes (10/2021)\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/single_sungaya/label_names.txt'\n",
    "\n",
    "with open(file_path) as file:\n",
    "    label_names = file.readlines()\n",
    "    label_names = [item.rstrip() for item in label_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"../data/single_sungaya/\"\n",
    "out_df = pd.read_hdf(os.path.join(target_dir, \"Data_3D_Pose.hdf5\"))\n",
    "reduceKeypoints = True\n",
    "sungaya_dataset = src.bug_dataset.BugDataset(df=out_df,\n",
    "                             root_dir=target_dir, reduced=reduceKeypoints, transform=transforms.Compose([\n",
    "                                src.bug_dataset.ToTensor()\n",
    "                                   ]))\n",
    "train_split = 0.7\n",
    "valid_split = 0.1\n",
    "train_size = int(train_split * len(sungaya_dataset))\n",
    "valid_size = int(valid_split * len(sungaya_dataset))\n",
    "test_size = len(sungaya_dataset) - (train_size+valid_size)\n",
    "train_dataset,_ ,test_dataset = torch.utils.data.random_split(sungaya_dataset, [train_size, valid_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PoseResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (deconv_layers): Sequential(\n",
       "    (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "  )\n",
       "  (final_layer): Conv2d(256, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))   \n",
    "\n",
    "# Load Models\n",
    "num_layers = 18\n",
    "resnet_spec = {18: (BasicBlock, [2, 2, 2, 2]),\n",
    "               34: (BasicBlock, [3, 4, 6, 3]),\n",
    "               50: (Bottleneck, [3, 4, 6, 3]),\n",
    "               101: (Bottleneck, [3, 4, 23, 3]),\n",
    "               152: (Bottleneck, [3, 8, 36, 3])}\n",
    "if reduceKeypoints:\n",
    "    block_class, layers = resnet_spec[num_layers]\n",
    "    model_2d = PoseResNet(block_class, layers, 28)\n",
    "\n",
    "else:\n",
    "    block_class, layers = resnet_spec[num_layers]\n",
    "    model_2d = PoseResNet(block_class, layers, 62)\n",
    "\n",
    "model_2d = model_2d.to(device)\n",
    "path = \"../models/2d_horiz_vertical_flip/simple_2d_model_20220321-195443_128\"\n",
    "model_2d.load_state_dict(torch.load(path))\n",
    "model_2d.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearModel(\n",
       "  (w1): Linear(in_features=56, out_features=1024, bias=True)\n",
       "  (batch_norm1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear_stages): ModuleList(\n",
       "    (0): Linear(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (w1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (batch_norm1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (w2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (batch_norm2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Linear(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (w1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (batch_norm1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (w2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (batch_norm2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (w2): Linear(in_features=1024, out_features=28, bias=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if reduceKeypoints:\n",
    "    model_lift = LinearModel(2*28,28,1024) # Linear size 512 looked promising 256 too small\n",
    "else:\n",
    "    model_lift = LinearModel(2*62,62,512)\n",
    "\n",
    "model_lift = model_lift.to(device)\n",
    "path = \"../models/lifting_depth/lifting_depth_model_20220323-150326_128\"\n",
    "model_lift.load_state_dict(torch.load(path))\n",
    "model_lift.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func(model_2d,model_lift, ds, frac_noise=0.0,thr=5.0):\n",
    "    test_epoch_acc, test_epoch_loss = 0, 0\n",
    "    test_epoch_acc_kps = [0]*28\n",
    "    batches = 0\n",
    "    # Code get the first batch of results\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(ds, desc=\"2-Stage Experiment\"):\n",
    "            input = data['image'].to(device, dtype=torch.float)\n",
    "            kp = data['key_points_2D'].to(device, dtype=torch.float)\n",
    "            y = data['key_points_3D'][:,:,2].to(device)\n",
    "            mask = data['visibility'].to(device)\n",
    "\n",
    "            \n",
    "            pred_heatmap =  model_2d(input)\n",
    "            \n",
    "            kps2d,_ = get_max_preds(pred_heatmap.detach().cpu().numpy())\n",
    "\n",
    "            # Add noise to the 2d input add guassian noise to determine how sensitve the model is that will give us a reason to why the model is working so badly\n",
    "            \n",
    "            ## Prints the using GT Noisey\n",
    "            # kps2d = kp.detach().cpu().numpy()\n",
    "            \n",
    "            # Normalise the data didnt think i needed to tho since the output of the model is already normalised nevemind silly me\n",
    "            kps2d = (torch.from_numpy(kps2d)-torch.stack([torch.Tensor(sungaya_dataset.means_2d)]*len(kps2d)))/torch.stack([torch.Tensor(sungaya_dataset.std_2d)]*len(kps2d))\n",
    "            kps2d = kps2d.reshape((len(kps2d), 56))\n",
    "            \n",
    "            if frac_noise > 0:\n",
    "                for bat in range(len(kps2d)):\n",
    "                    for col in range(len(kps2d[bat])):\n",
    "                        mean = abs(kps2d[:,col].mean())\n",
    "                        noise = np.random.normal(0,frac_noise*mean,len(kps2d[:,col]))\n",
    "                        kps2d[:,col] += noise\n",
    "\n",
    "            # Recentralise the data ? no idea what ive done here\n",
    "\n",
    "            # print(kps2d)\n",
    "            # kps2d = kps2d.detach().cpu().numpy()\n",
    "            # for x in range(len(kps2d)):\n",
    "            #     diff =  kps2d[x]\n",
    "            #     for i in range(len(kps2d[x])):\n",
    "            #         kps2d[x][i] = kps2d[x][i] - diff[i]\n",
    "            # kps2d = torch.from_numpy(kps2d).to(device)\n",
    "            # print(kps2d)\n",
    "\n",
    "            pred_lift = model_lift(kps2d.to(device))\n",
    "            # print(pred_lift.shape)\n",
    "            # print(y.shape)\n",
    "            pred_lift =(pred_lift*torch.stack([torch.Tensor(sungaya_dataset.std_3d[:,2])]*len(pred_lift)).to(device)) +torch.stack([torch.Tensor(sungaya_dataset.means_3d[:,2])]*len(pred_lift)).to(device)\n",
    "            for x in range(len(pred_lift)):\n",
    "                diff = abs(pred_lift[x,1] - y[x,1])\n",
    "                print(diff)\n",
    "                for i in range(len(pred_lift[x])):\n",
    "                    pred_lift[x][i] = pred_lift[x][i] - diff\n",
    "                print(pred_lift[x])\n",
    "            pred_lift = (pred_lift- torch.stack([torch.Tensor(sungaya_dataset.means_3d[:,2])]*len(pred_lift)).to(device)) /torch.stack([torch.Tensor(sungaya_dataset.std_3d[:,2])]*len(pred_lift)).to(device)\n",
    "\n",
    "\n",
    "            \n",
    "            test_loss = torch.mean(((pred_lift - y)*mask)**2) # \n",
    "                    \n",
    "            test_acc,test_acc_kps = keypoint_depth_pck(pred_lift.detach().cpu().numpy(),\n",
    "                                        y.detach().cpu().numpy(), \n",
    "                                        mask.detach().cpu().numpy(),\n",
    "                                        sungaya_dataset.std_3d[:,2], sungaya_dataset.means_3d[:,2], threshold = thr)\n",
    "            test_epoch_loss += test_loss.item()\n",
    "            test_epoch_acc += test_acc\n",
    "            test_epoch_acc_kps += test_acc_kps\n",
    "            batches +=1\n",
    "            \n",
    "    test_acc = test_epoch_acc/batches\n",
    "    test_acc_kps = test_epoch_acc_kps/batches\n",
    "    test_loss = test_epoch_loss/batches\n",
    "    return test_acc, test_loss, test_acc_kps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, test_loss, test_acc_kps = test_func(model_2d, model_lift, test_dataloader)\n",
    "# print(test_acc)\n",
    "# print(test_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the accuracies per KP at normal threshold\n",
    " \n",
    "fig, ax = plt.subplots(figsize=(11,8))\n",
    "\n",
    "ax.barh(np.array(label_names)[sungaya_dataset.reduced_kp], test_acc_kps, linewidth =5, edgecolor=\"white\")\n",
    "ax.invert_yaxis()\n",
    "# ax.set(xlim=(-1, 8), xticks=np.arange(-1, 8),\n",
    "#        ylim=(0, 1), yticks=np.arange(0, 0.5))\n",
    "plt.title(\"2 Stage PCK Accuracies for every Keypoint on Synthetic Data\")\n",
    "\n",
    "plt.xlabel(\"Accuracies\")\n",
    "plt.ylabel(\"Keypoints\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to do an experiment where we vary the threshold value on the test set\n",
    "thresholds = [0.01 ,0.1, 1.0, 2.5, 5.0, 10.0, 15.0, 20.0]\n",
    "accs = []\n",
    "losses = []\n",
    "acc_kps = []\n",
    "for thr in thresholds:\n",
    "    test_acc, test_loss, test_acc_kps = test_func(model_2d, model_lift, test_dataloader, thr=thr)\n",
    "    accs.append(test_acc)\n",
    "    losses.append(test_loss)\n",
    "    acc_kps.append(test_acc_kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots PCK for different thresholds\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(list(map(str,thresholds)), accs, width=1, edgecolor=\"white\", linewidth=5)\n",
    "\n",
    "plt.title(\"2 Stage PCK Accuracies at Varying Thresholds on Synthetic Data\")\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to do an experiment where we vary the amount of noise value on the test set\n",
    "frac_noise = [0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 0.7, 1.0]\n",
    "\n",
    "accs = []\n",
    "losses = []\n",
    "acc_kps = []\n",
    "for frac in frac_noise:\n",
    "    test_acc, test_loss, test_acc_kps = test_func(model_2d, model_lift, test_dataloader, frac_noise =frac)\n",
    "    accs.append(test_acc)\n",
    "    losses.append(test_loss)\n",
    "    acc_kps.append(test_acc_kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots PCK for different noise \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(list(map(str,frac_noise)), accs, width=1, edgecolor=\"white\", linewidth=5)\n",
    "\n",
    "plt.title(\"Lifting Model PCK Accuracies with Varying Noises on 2D GT Data\")\n",
    "plt.xlabel(\"Percentage Noise\")\n",
    "plt.ylabel(\"Accuracies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code get the first batch of results\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        image = data['file_name']\n",
    "        X = data['image'].to(device, dtype=torch.float)\n",
    "        y = data['key_points_3D'].to(device, dtype=torch.float)\n",
    "        vis = data['visibility']\n",
    "        \n",
    "        \n",
    "        pred_heatmap =  model_2d(X)\n",
    "        kps2d,_ = get_max_preds(pred_heatmap.detach().cpu().numpy())\n",
    "        kps2d = (torch.from_numpy(kps2d)-torch.stack([torch.Tensor(sungaya_dataset.means_2d)]*len(kps2d)))/torch.stack([torch.Tensor(sungaya_dataset.std_2d)]*len(kps2d))\n",
    "\n",
    "        kps2d = kps2d.reshape((len(kps2d), 56))\n",
    "        pred = model_lift(kps2d.to(device))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f5684ff8adb4c5dabb4694927df2c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "sample =10\n",
    "\n",
    "prediction = pred[sample].cpu().numpy()\n",
    "actual = (y[sample].cpu()).numpy()\n",
    "visibility_mask = vis[sample]\n",
    "\n",
    "mean = sungaya_dataset.means_3d[:,2]\n",
    "std = sungaya_dataset.std_3d[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "unnormalised_acc = (actual*sungaya_dataset.std_3d)+sungaya_dataset.means_3d\n",
    "ax, line1 = plot_stick_bug(ax, unnormalised_acc, visibility_mask)\n",
    "\n",
    "unnormalised_est = copy.deepcopy(unnormalised_acc)\n",
    "unnormalised_est[:,2] = (prediction*std)+mean\n",
    "\n",
    "# calculate distance from 1 kp\n",
    "diff  = abs( unnormalised_est[1,2] - unnormalised_acc[1,2] )\n",
    "for x in range(len(unnormalised_est)):\n",
    "    unnormalised_est[x,2] = unnormalised_est[x,2] - diff\n",
    "\n",
    "\n",
    "ax, line2 = plot_stick_bug(ax, unnormalised_est, visibility_mask, True)\n",
    "\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "ax.set_zlabel('Z axis')\n",
    "plt.title(image[sample])\n",
    "plt.legend(handles=[line1,line2], loc='upper right')\n",
    "\n",
    "# use custom function to ensure equal axis proportions\n",
    "set_axes_equal(ax)\n",
    "# opens external plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnormalised_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnormalised_est"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02436a74caeae32c2ef71ab76e7f86264abcd5d5376c75c1970567ef169e8611"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
