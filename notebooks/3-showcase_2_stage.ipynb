{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showcase 2-Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from src.models.simple_3d_model import LinearModel\n",
    "from src.models.pose_resnet import BasicBlock, PoseResNet, Bottleneck\n",
    "import src.bug_dataset\n",
    "from src.eval.accuracies import keypoint_depth_pck, get_max_preds\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Code\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_stick_bug(ax, points, vis, prediction=False):\n",
    "    limb_ranges=[[0,7],[8,14],[15,21],[22,28],[29,35],[36,42],[43,49],[53,56],[59,62]]\n",
    "    reduced_limb_ranges = [[0,4],[4,7],[7,10],[10,13],[13,16],[16,19],[19,22],[22,25],[25,28]]\n",
    "    if len(points) == 62:\n",
    "        points = np.array(points).T\n",
    "        for num in range(len(limb_ranges)):\n",
    "            visible_limb = []\n",
    "            for x in range(limb_ranges[num][0],limb_ranges[num][1]):\n",
    "                if vis[x]== 1:\n",
    "                    visible_limb.append(x) \n",
    "            if prediction:\n",
    "                line, = ax.plot(points[0][visible_limb], points[1][visible_limb], points[2][visible_limb],'--', alpha=0.7, label='Prediction', color='red')\n",
    "                ax.scatter(points[0][visible_limb], points[1][visible_limb], points[2][visible_limb], marker='X',s=10, color='red')\n",
    "            else:\n",
    "                line, = ax.plot(points[0][visible_limb], points[1][visible_limb], points[2][visible_limb], label='Actual', color='blue')\n",
    "                ax.scatter(points[0][visible_limb], points[1][visible_limb], points[2][visible_limb], marker='o',s=4, color='blue')\n",
    "        return ax, line\n",
    "    elif len(points) == 28:\n",
    "        points = np.array(points).T\n",
    "        for num in range(len(reduced_limb_ranges)):\n",
    "            visible_limb = []\n",
    "            for x in range(reduced_limb_ranges[num][0],reduced_limb_ranges[num][1]):\n",
    "                if vis[x]== 1:\n",
    "                    visible_limb.append(x) \n",
    "            if prediction:\n",
    "                line, = ax.plot(points[0][visible_limb], points[1][visible_limb], points[2][visible_limb],'--', alpha=0.7, label='Prediction', color='red')\n",
    "                ax.scatter(points[0][visible_limb], points[1][visible_limb], points[2][visible_limb], marker='X',s=10, color='red')\n",
    "            else:\n",
    "                line, = ax.plot(points[0][visible_limb], points[1][visible_limb], points[2][visible_limb], label='Actual', color='blue')\n",
    "                ax.scatter(points[0][visible_limb], points[1][visible_limb], points[2][visible_limb], marker='o',s=4, color='blue')\n",
    "        return ax, line\n",
    "\n",
    "def set_axes_equal(ax):\n",
    "    # workaround, as matplotlib's 3D plot has no option for equisised axes (10/2021)\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/single_sungaya/label_names.txt'\n",
    "\n",
    "with open(file_path) as file:\n",
    "    label_names = file.readlines()\n",
    "    label_names = [item.rstrip() for item in label_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"../data/single_sungaya/\"\n",
    "out_df = pd.read_hdf(os.path.join(target_dir, \"Data_3D_Pose.hdf5\"))\n",
    "reduceKeypoints = True\n",
    "sungaya_dataset = src.bug_dataset.BugDataset(df=out_df,\n",
    "                             root_dir=target_dir, reduced=reduceKeypoints, transform=transforms.Compose([\n",
    "                                src.bug_dataset.ToTensor()\n",
    "                                   ]))\n",
    "train_split = 0.7\n",
    "valid_split = 0.1\n",
    "train_size = int(train_split * len(sungaya_dataset))\n",
    "valid_size = int(valid_split * len(sungaya_dataset))\n",
    "test_size = len(sungaya_dataset) - (train_size+valid_size)\n",
    "train_dataset,_ ,test_dataset = torch.utils.data.random_split(sungaya_dataset, [train_size, valid_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))   \n",
    "\n",
    "# Load Models\n",
    "num_layers = 18\n",
    "resnet_spec = {18: (BasicBlock, [2, 2, 2, 2]),\n",
    "               34: (BasicBlock, [3, 4, 6, 3]),\n",
    "               50: (Bottleneck, [3, 4, 6, 3]),\n",
    "               101: (Bottleneck, [3, 4, 23, 3]),\n",
    "               152: (Bottleneck, [3, 8, 36, 3])}\n",
    "if reduceKeypoints:\n",
    "    block_class, layers = resnet_spec[num_layers]\n",
    "    model_2d = PoseResNet(block_class, layers, 28)\n",
    "\n",
    "else:\n",
    "    block_class, layers = resnet_spec[num_layers]\n",
    "    model_2d = PoseResNet(block_class, layers, 62)\n",
    "\n",
    "model_2d = model_2d.to(device)\n",
    "path = \"../models/2d_horiz_vertical_flip/simple_2d_model_20220321-195443_128\"\n",
    "model_2d.load_state_dict(torch.load(path))\n",
    "model_2d.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reduceKeypoints:\n",
    "    model_lift = LinearModel(2*28,28,1024) # Linear size 512 looked promising 256 too small\n",
    "else:\n",
    "    model_lift = LinearModel(2*62,62,512)\n",
    "\n",
    "model_lift = model_lift.to(device)\n",
    "path = \"../models/lifting_depth/lifting_depth_model_20220323-150326_128\"\n",
    "model_lift.load_state_dict(torch.load(path))\n",
    "model_lift.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code get the first batch of results\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        image = data['file_name']\n",
    "        X = data['image'].to(device, dtype=torch.float)\n",
    "        y = data['key_points_3D'].to(device, dtype=torch.float)\n",
    "        vis = data['visibility']\n",
    "        \n",
    "        \n",
    "        pred_heatmap =  model_2d(X)\n",
    "        kps2d,_ = get_max_preds(pred_heatmap.detach().cpu().numpy())\n",
    "        kps2d = (torch.from_numpy(kps2d)-torch.stack([torch.Tensor(sungaya_dataset.means_2d)]*len(kps2d)))/torch.stack([torch.Tensor(sungaya_dataset.std_2d)]*len(kps2d))\n",
    "\n",
    "        kps2d = kps2d.reshape((len(kps2d), 56))\n",
    "        pred = model_lift(kps2d.to(device))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "sample =10\n",
    "\n",
    "prediction = pred[sample].cpu().numpy()\n",
    "actual = (y[sample].cpu()).numpy()\n",
    "visibility_mask = vis[sample]\n",
    "\n",
    "mean = sungaya_dataset.means_3d[:,2]\n",
    "std = sungaya_dataset.std_3d[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "unnormalised_acc = (actual*sungaya_dataset.std_3d)+sungaya_dataset.means_3d\n",
    "ax, line1 = plot_stick_bug(ax, unnormalised_acc, visibility_mask)\n",
    "\n",
    "unnormalised_est = copy.deepcopy(unnormalised_acc)\n",
    "unnormalised_est[:,2] = (prediction*std)+mean\n",
    "\n",
    "# calculate distance from 1 kp\n",
    "diff  = abs( unnormalised_est[1,2] - unnormalised_acc[1,2] )\n",
    "for x in range(len(unnormalised_est)):\n",
    "    unnormalised_est[x,2] = unnormalised_est[x,2] - diff\n",
    "\n",
    "\n",
    "ax, line2 = plot_stick_bug(ax, unnormalised_est, visibility_mask, True)\n",
    "\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "ax.set_zlabel('Z axis')\n",
    "plt.title(image[sample])\n",
    "plt.legend(handles=[line1,line2], loc='upper right')\n",
    "\n",
    "# use custom function to ensure equal axis proportions\n",
    "set_axes_equal(ax)\n",
    "# opens external plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02436a74caeae32c2ef71ab76e7f86264abcd5d5376c75c1970567ef169e8611"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
